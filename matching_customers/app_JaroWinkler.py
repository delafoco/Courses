import streamlit as st
import pandas as pd
import numpy as np
from fuzzywuzzy import fuzz
from unidecode import unidecode
import matplotlib.pyplot as plt

# Configuration de la page Streamlit
st.set_page_config(
    page_title="Simulation de Matching Client",
    page_icon="üîç",
    layout="wide"
)

# Fonction de g√©n√©ration de donn√©es
def generate_data(num_clients, error_rate=0.1):
    data = []
    
    # Liste plus large de noms et pr√©noms pour plus de variations
    noms = ["Martin", "Dubois", "Thomas", "Richard", "Petit", "Durand", "Leroy", "Moreau", "Simon", "Laurent",
            "Bernard", "Robert", "Michel", "Garcia", "David", "Bertrand", "Roux", "Vincent", "Fournier", "Morel"]
    prenoms = ["Jean", "Marie", "Pierre", "Michel", "Sophie", "Catherine", "Nicolas", "Isabelle", "Philippe", "Anne",
               "Claude", "Lucas", "Emma", "L√©a", "Hugo", "Louis", "Jules", "Alice", "Lina", "Noah"]
    
    for i in range(num_clients):
        nom = noms[i % len(noms)]
        prenom = prenoms[i % len(prenoms)]
        id_vehicule = f"VEH{i:05d}"
        immatriculation = f"AB-{i%999:03d}-CD"
        email = f"{prenom.lower()}.{nom.lower()}@example.com"
        telephone = f"01{i%99:02d}345678"
        
        # Introduire des erreurs al√©atoires pour simuler des donn√©es h√©t√©rog√®nes
        if np.random.rand() < error_rate:
            # Erreurs plus vari√©es dans le nom
            error_type = np.random.choice(['suppression', 'ajout', 'substitution', 'inversion'])
            if error_type == 'suppression':
                nom = nom[:-1] if len(nom) > 3 else nom
            elif error_type == 'ajout':
                nom = nom + ('e' if nom[-1] != 'e' else 'a')
            elif error_type == 'substitution':
                pos = np.random.randint(0, len(nom))
                nom = nom[:pos] + ('e' if nom[pos] != 'e' else 'a') + nom[pos+1:]
            else:  # inversion
                if len(nom) > 3:
                    pos = np.random.randint(0, len(nom)-1)
                    nom = nom[:pos] + nom[pos+1] + nom[pos] + nom[pos+2:]
        
        if np.random.rand() < error_rate:
            # Erreurs plus vari√©es dans le pr√©nom
            error_type = np.random.choice(['suppression', 'ajout', 'substitution', 'inversion'])
            if error_type == 'suppression':
                prenom = prenom[:-1] if len(prenom) > 3 else prenom
            elif error_type == 'ajout':
                prenom = prenom + ('s' if prenom[-1] != 's' else 'e')
            elif error_type == 'substitution':
                pos = np.random.randint(0, len(prenom))
                prenom = prenom[:pos] + ('e' if prenom[pos] != 'e' else 'a') + prenom[pos+1:]
            else:  # inversion
                if len(prenom) > 3:
                    pos = np.random.randint(0, len(prenom)-1)
                    prenom = prenom[:pos] + prenom[pos+1] + prenom[pos] + prenom[pos+2:]
        
        if np.random.rand() < error_rate:
            # Erreurs plus vari√©es dans l'email
            error_type = np.random.choice(['domaine', 'format', 'caract√®res'])
            if error_type == 'domaine':
                email = email.replace('@example.com', '@gmail.com')
            elif error_type == 'format':
                email = email.replace('.', '_')
            else:  # caract√®res
                email = email.replace('a', '4').replace('e', '3').replace('i', '1').replace('o', '0')
        
        if np.random.rand() < error_rate:
            # Erreurs plus vari√©es dans le t√©l√©phone
            error_type = np.random.choice(['format', 'chiffres', 'longueur'])
            if error_type == 'format':
                telephone = telephone.replace('-', ' ').replace(' ', '')
            elif error_type == 'chiffres':
                pos = np.random.randint(0, len(telephone))
                telephone = telephone[:pos] + str(np.random.randint(0, 10)) + telephone[pos+1:]
            else:  # longueur
                if np.random.rand() < 0.5:
                    telephone = telephone[:-1]  # trop court
                else:
                    telephone = telephone + str(np.random.randint(0, 10))  # trop long
        
        # Ajouter des erreurs dans l'ID v√©hicule
        if np.random.rand() < error_rate:
            error_type = np.random.choice(['chiffres', 'format', 'longueur'])
            if error_type == 'chiffres':
                pos = np.random.randint(3, len(id_vehicule))
                id_vehicule = id_vehicule[:pos] + str(np.random.randint(0, 10)) + id_vehicule[pos+1:]
            elif error_type == 'format':
                id_vehicule = id_vehicule.replace('VEH', 'VH')
            else:  # longueur
                if np.random.rand() < 0.5:
                    id_vehicule = id_vehicule[:-1]  # trop court
                else:
                    id_vehicule = id_vehicule + str(np.random.randint(0, 10))  # trop long
        
        # Ajouter des erreurs dans l'immatriculation
        if np.random.rand() < error_rate:
            error_type = np.random.choice(['chiffres', 'format', 'lettres'])
            if error_type == 'chiffres':
                pos = np.random.randint(3, 6)
                immatriculation = immatriculation[:pos] + str(np.random.randint(0, 10)) + immatriculation[pos+1:]
            elif error_type == 'format':
                immatriculation = immatriculation.replace('-', ' ')
            else:  # lettres
                pos = np.random.randint(0, 2)
                immatriculation = immatriculation[:pos] + chr(np.random.randint(65, 91)) + immatriculation[pos+1:]
        
        data.append({
            'Nom': nom,
            'Pr√©nom': prenom,
            'ID_V√©hicule': id_vehicule,
            'Immatriculation': immatriculation,
            'Email': email,
            'T√©l√©phone': telephone,
            'Date': pd.Timestamp.now() - pd.Timedelta(days=np.random.randint(1, 100))
        })
        
        # Ajouter des doublons avec des variations plus importantes
        if i % 5 == 0:
            nom_alt = nom
            prenom_alt = prenom
            email_alt = email
            telephone_alt = telephone
            id_vehicule_alt = id_vehicule
            immatriculation_alt = immatriculation
            
            # Variations plus importantes pour les doublons
            if np.random.rand() < 0.3:
                nom_alt = nom.upper()
            if np.random.rand() < 0.3:
                prenom_alt = prenom.upper()
            if np.random.rand() < 0.3:
                # Variations d'email plus importantes
                email_variations = [
                    email.replace('@example.com', '@gmail.com'),
                    email.replace('.', '_'),
                    email.replace('a', '4').replace('e', '3').replace('i', '1').replace('o', '0'),
                    f"{prenom.lower()}{nom.lower()}@example.com",
                    f"{nom.lower()}.{prenom.lower()}@example.com"
                ]
                email_alt = np.random.choice(email_variations)
            if np.random.rand() < 0.3:
                # Variations de t√©l√©phone plus importantes
                telephone_variations = [
                    telephone.replace('-', ' ').replace(' ', ''),
                    telephone.replace('01', '06'),
                    telephone.replace('01', '07'),
                    telephone[:-1] + str(np.random.randint(0, 10)),
                    telephone + str(np.random.randint(0, 10))
                ]
                telephone_alt = np.random.choice(telephone_variations)
            if np.random.rand() < 0.3:
                # Variations d'ID v√©hicule plus importantes
                id_vehicule_variations = [
                    id_vehicule.replace('VEH', 'VH'),
                    id_vehicule.replace('VEH', 'VEH-'),
                    id_vehicule[:-1] + str(np.random.randint(0, 10)),
                    id_vehicule + str(np.random.randint(0, 10))
                ]
                id_vehicule_alt = np.random.choice(id_vehicule_variations)
            if np.random.rand() < 0.3:
                # Variations d'immatriculation plus importantes
                immatriculation_variations = [
                    immatriculation.replace('-', ' '),
                    immatriculation.replace('AB', 'BA'),
                    immatriculation.replace('CD', 'DC'),
                    immatriculation.replace('-', '')
                ]
                immatriculation_alt = np.random.choice(immatriculation_variations)
                
            data.append({
                'Nom': nom_alt,
                'Pr√©nom': prenom_alt,
                'ID_V√©hicule': id_vehicule_alt,
                'Immatriculation': immatriculation_alt,
                'Email': email_alt,
                'T√©l√©phone': telephone_alt,
                'Date': pd.Timestamp.now() - pd.Timedelta(days=np.random.randint(1, 100))
            })
            
    return pd.DataFrame(data)

def normalize_string(s):
    """Convertit une cha√Æne en minuscules et supprime les accents."""
    return unidecode(str(s).lower())

def calculate_similarity_score(str1, str2):
    """Calcule le score de similarit√© entre deux cha√Ænes."""
    # Si exactement identiques
    if str1 == str2:
        return 100
    
    # Sinon, utiliser le score de similarit√© brut
    return fuzz.ratio(normalize_string(str1), normalize_string(str2))

def match_clients(client_a, client_b, weights):
    # Calcul des scores individuels avec normalisation des cha√Ænes
    nom_score = calculate_similarity_score(client_a['Nom'], client_b['Nom'])
    prenom_score = calculate_similarity_score(client_a['Pr√©nom'], client_b['Pr√©nom'])
    telephone_score = calculate_similarity_score(client_a['T√©l√©phone'], client_b['T√©l√©phone'])
    email_score = calculate_similarity_score(client_a['Email'], client_b['Email'])
    id_vehicule_score = calculate_similarity_score(client_a['ID_V√©hicule'], client_b['ID_V√©hicule'])
    immatriculation_score = calculate_similarity_score(client_a['Immatriculation'], client_b['Immatriculation'])
    
    # Calcul du score moyen
    score = (nom_score + prenom_score + email_score + telephone_score + id_vehicule_score + immatriculation_score) / 6
    
    return score, {
        'Nom': nom_score,
        'Pr√©nom': prenom_score,
        'Email': email_score,
        'T√©l√©phone': telephone_score,
        'ID_V√©hicule': id_vehicule_score,
        'Immatriculation': immatriculation_score
    }

# Simulation de matching
def simulate_matching(clients, weights, threshold):
    matches = []
    
    # Cr√©er un dictionnaire pour stocker les groupes de clients
    client_groups = {}
    next_group_id = 0
    
    # Comparer tous les clients entre eux
    for i, client_a in clients.iterrows():
        for j, client_b in clients.iterrows():
            if i < j:  # √âviter les comparaisons en double
                score, detail_scores = match_clients(client_a, client_b, weights)
                
                if score >= threshold:
                    matches.append({
                        'Client A': client_a['Nom'] + ' ' + client_a['Pr√©nom'],
                        'Client B': client_b['Nom'] + ' ' + client_b['Pr√©nom'],
                        'Score Global': score,
                        'Score Nom': detail_scores['Nom'],
                        'Score Pr√©nom': detail_scores['Pr√©nom'],
                        'Score Email': detail_scores['Email'],
                        'Score T√©l√©phone': detail_scores['T√©l√©phone'],
                        'Score ID V√©hicule': detail_scores['ID_V√©hicule'],
                        'Score Immatriculation': detail_scores['Immatriculation']
                    })
                    
                    # Regrouper les clients
                    if i in client_groups and j in client_groups:
                        # Les deux clients ont d√©j√† des groupes, fusionner les groupes
                        group_a = client_groups[i]
                        group_b = client_groups[j]
                        if group_a != group_b:
                            for idx in client_groups:
                                if client_groups[idx] == group_b:
                                    client_groups[idx] = group_a
                    elif i in client_groups:
                        # Seulement le client A a un groupe, ajouter B au m√™me groupe
                        client_groups[j] = client_groups[i]
                    elif j in client_groups:
                        # Seulement le client B a un groupe, ajouter A au m√™me groupe
                        client_groups[i] = client_groups[j]
                    else:
                        # Aucun des clients n'a de groupe, cr√©er un nouveau groupe
                        client_groups[i] = next_group_id
                        client_groups[j] = next_group_id
                        next_group_id += 1
    
    return pd.DataFrame(matches), client_groups

# Application Streamlit
def main():
    st.title("üîç Simulation de Matching Client")
    st.markdown("""
    Cette application simule un syst√®me de matching client pour identifier et regrouper les √©v√©nements appartenant au m√™me client.
    Utilisez les contr√¥les ci-dessous pour configurer la simulation et analyser les r√©sultats.
    """)
    
    # Sidebar pour les param√®tres
    st.sidebar.title("Param√®tres")
    
    # Explication des scores et seuils
    with st.sidebar.expander("‚ÑπÔ∏è Comprendre les scores et seuils"):
        st.markdown("""
        ### Calcul des scores
        - Chaque attribut (Nom, Pr√©nom, Email, T√©l√©phone) re√ßoit un score de similarit√© entre 0 et 100.
        - La m√©thode Jaro-Winkler est utilis√©e pour calculer la similarit√© entre deux cha√Ænes.
        - Le score global est la moyenne des scores individuels.

        ### La confiance √† confier aux diff√©rents seuils 
        - **Score global > 90%** : Correspondance quasi-certaine (tr√®s faible risque de faux positif)
        - **Score global 80-90%** : Bonne correspondance probable (faible risque de faux positif)
        - **Score global 70-80%** : Correspondance possible (risque mod√©r√© de faux positif)
        - **Score global < 70%** : Correspondance incertaine (risque √©lev√© de faux positif)

        ### Scores par attribut
        - **> 90** : Attributs identiques ou tr√®s similaires
        - **70-90** : Attributs similaires avec quelques diff√©rences
        - **50-70** : Attributs partiellement similaires
        - **< 50** : Attributs diff√©rents
        """)
    
    # Configuration des donn√©es
    st.sidebar.subheader("Configuration des donn√©es")
    num_clients = st.sidebar.slider("Nombre de clients √† g√©n√©rer", 10, 200, 50)
    error_rate = st.sidebar.slider("Taux d'erreur dans les donn√©es", 0.0, 0.5, 0.1, 
                                help="Pourcentage d'erreurs introduites dans les donn√©es pour simuler des donn√©es h√©t√©rog√®nes")
    
    # Seuil de similarit√©
    threshold = st.sidebar.slider("Seuil de similarit√© (%)", 0, 100, 80,
                               help="Score minimal pour consid√©rer deux clients comme identiques")
    
    # Affichage du seuil avec code couleur
    threshold_color = "#ff0000" if threshold < 70 else "#ffa500" if threshold < 80 else "#008000"
    st.sidebar.markdown(f"""
    <div style='background-color: {threshold_color}; padding: 10px; border-radius: 5px; color: white;'>
    Seuil actuel: <strong>{threshold}%</strong><br>
    Risque de faux positifs: <strong>{'√âlev√©' if threshold < 70 else 'Mod√©r√©' if threshold < 80 else 'Faible'}</strong>
    </div>
    """, unsafe_allow_html=True)
    
    # G√©n√©ration des donn√©es
    if st.button("G√©n√©rer des donn√©es et lancer le matching"):
        with st.spinner("G√©n√©ration des donn√©es en cours..."):
            clients = generate_data(num_clients, error_rate)
            
        st.subheader("Donn√©es clients g√©n√©r√©es")
        st.dataframe(clients)
        
        with st.spinner("Matching des clients en cours..."):
            matches_df, client_groups = simulate_matching(clients, {}, threshold)
        
        # Affichage des r√©sultats
        st.subheader("R√©sultats du matching")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"Nombre total de matches trouv√©s : {len(matches_df)}")
            
            # Regrouper les clients en groupes
            groups = {}
            for idx, group_id in client_groups.items():
                if group_id not in groups:
                    groups[group_id] = []
                groups[group_id].append(idx)
            
            st.write(f"Nombre de groupes de clients identifi√©s : {len(groups)}")
        
        with col2:
            # Calculer les statistiques sur les scores
            if not matches_df.empty:
                st.write("Statistiques des scores :")
                score_mean = matches_df['Score Global'].mean()
                score_min = matches_df['Score Global'].min()
                score_max = matches_df['Score Global'].max()
                
                st.write(f"Score moyen : {score_mean:.2f}")
                st.write(f"Score minimum : {score_min:.2f}")
                st.write(f"Score maximum : {score_max:.2f}")
                
                # Indications sur la qualit√© des matches
                score_quality = "Excellente" if score_mean > 90 else "Bonne" if score_mean > 80 else "Moyenne" if score_mean > 70 else "Faible"
                st.markdown(f"**Qualit√© globale des matches: {score_quality}**")
        
        # Afficher les matches trouv√©s
        if not matches_df.empty:
            st.subheader("Exemples de comparaisons par niveau de qualit√©")
            
            # Cr√©er un DataFrame avec les d√©tails des clients
            comparison_data = []
            for _, match in matches_df.iterrows():
                client_a = clients[clients['Nom'] + ' ' + clients['Pr√©nom'] == match['Client A']].iloc[0]
                client_b = clients[clients['Nom'] + ' ' + clients['Pr√©nom'] == match['Client B']].iloc[0]
                
                # Calculer la qualit√© en fonction du score
                qualite = "‚úÖ Excellente" if match['Score Global'] > 90 else "‚úÖ Bonne" if match['Score Global'] > 80 else "‚ö†Ô∏è Moyenne" if match['Score Global'] > 70 else "‚ùå Faible"
                
                comparison_data.append({
                    'Score Global': match['Score Global'],
                    'Qualit√©': qualite,
                    'Client A - Nom': client_a['Nom'],
                    'Client A - Pr√©nom': client_a['Pr√©nom'],
                    'Client A - Email': client_a['Email'],
                    'Client A - T√©l√©phone': client_a['T√©l√©phone'],
                    'Client A - ID_V√©hicule': client_a['ID_V√©hicule'],
                    'Client A - Immatriculation': client_a['Immatriculation'],
                    'Client B - Nom': client_b['Nom'],
                    'Client B - Pr√©nom': client_b['Pr√©nom'],
                    'Client B - Email': client_b['Email'],
                    'Client B - T√©l√©phone': client_b['T√©l√©phone'],
                    'Client B - ID_V√©hicule': client_b['ID_V√©hicule'],
                    'Client B - Immatriculation': client_b['Immatriculation'],
                    'Score Nom': match['Score Nom'],
                    'Score Pr√©nom': match['Score Pr√©nom'],
                    'Score Email': match['Score Email'],
                    'Score T√©l√©phone': match['Score T√©l√©phone'],
                    'Score ID V√©hicule': match['Score ID V√©hicule'],
                    'Score Immatriculation': match['Score Immatriculation']
                })
            
            comparison_df = pd.DataFrame(comparison_data)
            
            # Grouper par qualit√© et s√©lectionner 3 exemples pour chaque niveau
            quality_groups = {
                "‚úÖ Excellente": comparison_df[comparison_df['Score Global'] > 90],
                "‚úÖ Bonne": comparison_df[(comparison_df['Score Global'] > 80) & (comparison_df['Score Global'] <= 90)],
                "‚ö†Ô∏è Moyenne": comparison_df[(comparison_df['Score Global'] > 70) & (comparison_df['Score Global'] <= 80)],
                "‚ùå Faible": comparison_df[comparison_df['Score Global'] <= 70]
            }
            
            for quality, group in quality_groups.items():
                if not group.empty:
                    st.markdown(f"### {quality}")
                    # S√©lectionner 3 exemples al√©atoires
                    examples = group.sample(n=min(3, len(group)))
                    
                    for _, row in examples.iterrows():
                        with st.expander(f"Score Global: {row['Score Global']:.1f}%"):
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.markdown("**Client A**")
                                st.write(f"Nom: {row['Client A - Nom']}")
                                st.write(f"Pr√©nom: {row['Client A - Pr√©nom']}")
                                st.write(f"Email: {row['Client A - Email']}")
                                st.write(f"T√©l√©phone: {row['Client A - T√©l√©phone']}")
                                st.write(f"ID V√©hicule: {row['Client A - ID_V√©hicule']}")
                                st.write(f"Immatriculation: {row['Client A - Immatriculation']}")
                            
                            with col2:
                                st.markdown("**Client B**")
                                st.write(f"Nom: {row['Client B - Nom']}")
                                st.write(f"Pr√©nom: {row['Client B - Pr√©nom']}")
                                st.write(f"Email: {row['Client B - Email']}")
                                st.write(f"T√©l√©phone: {row['Client B - T√©l√©phone']}")
                                st.write(f"ID V√©hicule: {row['Client B - ID_V√©hicule']}")
                                st.write(f"Immatriculation: {row['Client B - Immatriculation']}")
                            
                            st.markdown("**Scores par attribut**")
                            col3, col4, col5, col6, col7, col8 = st.columns(6)
                            
                            with col3:
                                st.metric("Score Nom", f"{row['Score Nom']:.1f}%")
                            with col4:
                                st.metric("Score Pr√©nom", f"{row['Score Pr√©nom']:.1f}%")
                            with col5:
                                st.metric("Score Email", f"{row['Score Email']:.1f}%")
                            with col6:
                                st.metric("Score T√©l√©phone", f"{row['Score T√©l√©phone']:.1f}%")
                            with col7:
                                st.metric("Score ID V√©hicule", f"{row['Score ID V√©hicule']:.1f}%")
                            with col8:
                                st.metric("Score Immatriculation", f"{row['Score Immatriculation']:.1f}%")
                            
                            # Afficher le score global
                            st.markdown(f"""
                            **Score Global: {row['Score Global']:.1f}%**
                            
                            *Note: Le score global est la moyenne des scores individuels de chaque attribut.*
                            """)
            
            # Distribution des scores
            st.subheader("Distribution des scores")
            fig, ax = plt.subplots(figsize=(10, 4))
            ax.hist(matches_df['Score Global'], bins=20, color='#3498db', alpha=0.7)
            ax.axvline(x=90, color='green', linestyle='--', label='Excellent (>90)')
            ax.axvline(x=80, color='orange', linestyle='--', label='Bon (>80)')
            ax.axvline(x=70, color='red', linestyle='--', label='Moyen (>70)')
            ax.set_xlabel('Score global')
            ax.set_ylabel('Nombre de matches')
            ax.legend()
            st.pyplot(fig)
            
            # Visualisation des groupes de clients
            st.subheader("Groupes de clients identifi√©s")
            for group_id, indices in groups.items():
                with st.expander(f"Groupe {group_id} ({len(indices)} clients)"):
                    st.dataframe(clients.iloc[indices])
        else:
            st.info("Aucun match trouv√© avec les param√®tres actuels. Essayez de r√©duire le seuil de similarit√© ou d'ajuster les poids des attributs.")
        
        # Analyse des performances
        st.subheader("Analyse des performances des attributs")
        if not matches_df.empty:
            # Cr√©er un graphique des scores par attribut
            fig, ax = plt.subplots(figsize=(10, 6))
            
            attributes = ['Score Nom', 'Score Pr√©nom', 'Score Email', 'Score T√©l√©phone', 'Score ID V√©hicule', 'Score Immatriculation']
            means = [matches_df[attr].mean() for attr in attributes]
            
            # D√©finir les couleurs en fonction des scores
            colors = []
            for mean in means:
                if mean > 90:
                    colors.append('#2ecc71')  # vert - excellent
                elif mean > 80:
                    colors.append('#27ae60')  # vert fonc√© - bon
                elif mean > 70:
                    colors.append('#f39c12')  # orange - moyen
                elif mean > 50:
                    colors.append('#e67e22')  # orange fonc√© - faible
                else:
                    colors.append('#e74c3c')  # rouge - tr√®s faible
            
            ax.bar(attributes, means, color=colors)
            ax.set_ylim(0, 100)
            ax.set_ylabel('Score moyen')
            ax.set_title('Score moyen par attribut')
            
            # Ajouter des lignes de r√©f√©rence
            ax.axhline(y=90, color='green', linestyle='--', alpha=0.5)
            ax.axhline(y=70, color='red', linestyle='--', alpha=0.5)
            
            # Ajouter les valeurs sur les barres
            for i, v in enumerate(means):
                ax.text(i, v + 2, f"{v:.1f}", ha='center')
            
            st.pyplot(fig)
            
            # Recommandations
            st.subheader("Recommandations")
            
            recommendations = []
            
            # Analyser l'efficacit√© des attributs
            low_score_attributes = [(attr.replace('Score ', ''), score) for attr, score in zip(attributes, means) if score < 70]
            if low_score_attributes:
                for attr, score in low_score_attributes:
                    recommendations.append(f"L'attribut '{attr}' a un score moyen bas ({score:.1f}). Consid√©rez am√©liorer la qualit√© des donn√©es pour cet attribut.")
            
            # Analyser le seuil
            if matches_df['Score Global'].min() < threshold * 0.9:
                recommendations.append(f"Certains matches ont un score proche du seuil ({threshold}). Consid√©rez ajuster l√©g√®rement le seuil pour √©viter les faux n√©gatifs.")
            
            if not recommendations:
                recommendations.append("Le mod√®le de matching semble bien fonctionner avec les param√®tres actuels.")
            
            for rec in recommendations:
                st.write(f"‚Ä¢ {rec}")
            
            # Tableau des seuils recommand√©s
            st.subheader("Guide des seuils recommand√©s")
            seuil_df = pd.DataFrame({
                "Seuil": ["90% et plus", "80% - 90%", "70% - 80%", "Moins de 70%"],
                "Interpr√©tation": [
                    "Correspondance quasi-certaine", 
                    "Bonne correspondance probable", 
                    "Correspondance possible", 
                    "Correspondance incertaine"
                ],
                "Risque de faux positifs": ["Tr√®s faible", "Faible", "Mod√©r√©", "√âlev√©"],
                "Recommandation": [
                    "Associer automatiquement les clients", 
                    "Associer les clients avec v√©rification p√©riodique", 
                    "V√©rification manuelle recommand√©e", 
                    "Ne pas associer automatiquement"
                ]
            })
            st.table(seuil_df)

if __name__ == "__main__":
    main() 