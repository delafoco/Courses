import streamlit as st
import pandas as pd
import numpy as np
from fuzzywuzzy import fuzz
from unidecode import unidecode
import matplotlib.pyplot as plt

# Configuration de la page Streamlit
st.set_page_config(
    page_title="Simulation de Matching Client",
    page_icon="üîç",
    layout="wide"
)

# Fonction de g√©n√©ration de donn√©es
def generate_data(num_clients, error_rate=0.1):
    data = []
    
    # Liste plus large de noms et pr√©noms pour plus de variations
    noms = ["Martin", "Dubois", "Thomas", "Richard", "Petit", "Durand", "Leroy", "Moreau", "Simon", "Laurent",
            "Bernard", "Robert", "Michel", "Garcia", "David", "Bertrand", "Roux", "Vincent", "Fournier", "Morel"]
    prenoms = ["Jean", "Marie", "Pierre", "Michel", "Sophie", "Catherine", "Nicolas", "Isabelle", "Philippe", "Anne",
               "Claude", "Lucas", "Emma", "L√©a", "Hugo", "Louis", "Jules", "Alice", "Lina", "Noah"]
    
    for i in range(num_clients):
        nom = noms[i % len(noms)]
        prenom = prenoms[i % len(prenoms)]
        id_vehicule = f"VEH{i:05d}"
        immatriculation = f"AB-{i%999:03d}-CD"
        email = f"{prenom.lower()}.{nom.lower()}@example.com"
        telephone = f"01{i%99:02d}345678"
        
        # Introduire des erreurs al√©atoires pour simuler des donn√©es h√©t√©rog√®nes
        if np.random.rand() < error_rate:
            # Erreurs plus vari√©es dans le nom
            error_type = np.random.choice(['suppression', 'ajout', 'substitution', 'inversion'])
            if error_type == 'suppression':
                nom = nom[:-1] if len(nom) > 3 else nom
            elif error_type == 'ajout':
                nom = nom + ('e' if nom[-1] != 'e' else 'a')
            elif error_type == 'substitution':
                pos = np.random.randint(0, len(nom))
                nom = nom[:pos] + ('e' if nom[pos] != 'e' else 'a') + nom[pos+1:]
            else:  # inversion
                if len(nom) > 3:
                    pos = np.random.randint(0, len(nom)-1)
                    nom = nom[:pos] + nom[pos+1] + nom[pos] + nom[pos+2:]
        
        if np.random.rand() < error_rate:
            # Erreurs plus vari√©es dans le pr√©nom
            error_type = np.random.choice(['suppression', 'ajout', 'substitution', 'inversion'])
            if error_type == 'suppression':
                prenom = prenom[:-1] if len(prenom) > 3 else prenom
            elif error_type == 'ajout':
                prenom = prenom + ('s' if prenom[-1] != 's' else 'e')
            elif error_type == 'substitution':
                pos = np.random.randint(0, len(prenom))
                prenom = prenom[:pos] + ('e' if prenom[pos] != 'e' else 'a') + prenom[pos+1:]
            else:  # inversion
                if len(prenom) > 3:
                    pos = np.random.randint(0, len(prenom)-1)
                    prenom = prenom[:pos] + prenom[pos+1] + prenom[pos] + prenom[pos+2:]
        
        if np.random.rand() < error_rate:
            # Erreurs plus vari√©es dans l'email
            error_type = np.random.choice(['domaine', 'format', 'caract√®res'])
            if error_type == 'domaine':
                email = email.replace('@example.com', '@gmail.com')
            elif error_type == 'format':
                email = email.replace('.', '_')
            else:  # caract√®res
                email = email.replace('a', '4').replace('e', '3').replace('i', '1').replace('o', '0')
        
        if np.random.rand() < error_rate:
            # Erreurs plus vari√©es dans le t√©l√©phone
            error_type = np.random.choice(['format', 'chiffres', 'longueur'])
            if error_type == 'format':
                telephone = telephone.replace('-', ' ').replace(' ', '')
            elif error_type == 'chiffres':
                pos = np.random.randint(0, len(telephone))
                telephone = telephone[:pos] + str(np.random.randint(0, 10)) + telephone[pos+1:]
            else:  # longueur
                if np.random.rand() < 0.5:
                    telephone = telephone[:-1]  # trop court
                else:
                    telephone = telephone + str(np.random.randint(0, 10))  # trop long
        
        # Ajouter des erreurs dans l'ID v√©hicule
        if np.random.rand() < error_rate:
            error_type = np.random.choice(['chiffres', 'format', 'longueur'])
            if error_type == 'chiffres':
                pos = np.random.randint(3, len(id_vehicule))
                id_vehicule = id_vehicule[:pos] + str(np.random.randint(0, 10)) + id_vehicule[pos+1:]
            elif error_type == 'format':
                id_vehicule = id_vehicule.replace('VEH', 'VH')
            else:  # longueur
                if np.random.rand() < 0.5:
                    id_vehicule = id_vehicule[:-1]  # trop court
                else:
                    id_vehicule = id_vehicule + str(np.random.randint(0, 10))  # trop long
        
        # Ajouter des erreurs dans l'immatriculation
        if np.random.rand() < error_rate:
            error_type = np.random.choice(['chiffres', 'format', 'lettres'])
            if error_type == 'chiffres':
                pos = np.random.randint(3, 6)
                immatriculation = immatriculation[:pos] + str(np.random.randint(0, 10)) + immatriculation[pos+1:]
            elif error_type == 'format':
                immatriculation = immatriculation.replace('-', ' ')
            else:  # lettres
                pos = np.random.randint(0, 2)
                immatriculation = immatriculation[:pos] + chr(np.random.randint(65, 91)) + immatriculation[pos+1:]
        
        data.append({
            'Nom': nom,
            'Pr√©nom': prenom,
            'ID_V√©hicule': id_vehicule,
            'Immatriculation': immatriculation,
            'Email': email,
            'T√©l√©phone': telephone,
            'Date': pd.Timestamp.now() - pd.Timedelta(days=np.random.randint(1, 100))
        })
        
        # Ajouter des doublons avec des variations plus importantes
        if i % 5 == 0:
            nom_alt = nom
            prenom_alt = prenom
            email_alt = email
            telephone_alt = telephone
            id_vehicule_alt = id_vehicule
            immatriculation_alt = immatriculation
            
            # Variations plus importantes pour les doublons
            if np.random.rand() < 0.3:
                nom_alt = nom.upper()
            if np.random.rand() < 0.3:
                prenom_alt = prenom.upper()
            if np.random.rand() < 0.3:
                # Variations d'email plus importantes
                email_variations = [
                    email.replace('@example.com', '@gmail.com'),
                    email.replace('.', '_'),
                    email.replace('a', '4').replace('e', '3').replace('i', '1').replace('o', '0'),
                    f"{prenom.lower()}{nom.lower()}@example.com",
                    f"{nom.lower()}.{prenom.lower()}@example.com"
                ]
                email_alt = np.random.choice(email_variations)
            if np.random.rand() < 0.3:
                # Variations de t√©l√©phone plus importantes
                telephone_variations = [
                    telephone.replace('-', ' ').replace(' ', ''),
                    telephone.replace('01', '06'),
                    telephone.replace('01', '07'),
                    telephone[:-1] + str(np.random.randint(0, 10)),
                    telephone + str(np.random.randint(0, 10))
                ]
                telephone_alt = np.random.choice(telephone_variations)
            if np.random.rand() < 0.3:
                # Variations d'ID v√©hicule plus importantes
                id_vehicule_variations = [
                    id_vehicule.replace('VEH', 'VH'),
                    id_vehicule.replace('VEH', 'VEH-'),
                    id_vehicule[:-1] + str(np.random.randint(0, 10)),
                    id_vehicule + str(np.random.randint(0, 10))
                ]
                id_vehicule_alt = np.random.choice(id_vehicule_variations)
            if np.random.rand() < 0.3:
                # Variations d'immatriculation plus importantes
                immatriculation_variations = [
                    immatriculation.replace('-', ' '),
                    immatriculation.replace('AB', 'BA'),
                    immatriculation.replace('CD', 'DC'),
                    immatriculation.replace('-', '')
                ]
                immatriculation_alt = np.random.choice(immatriculation_variations)
                
            data.append({
                'Nom': nom_alt,
                'Pr√©nom': prenom_alt,
                'ID_V√©hicule': id_vehicule_alt,
                'Immatriculation': immatriculation_alt,
                'Email': email_alt,
                'T√©l√©phone': telephone_alt,
                'Date': pd.Timestamp.now() - pd.Timedelta(days=np.random.randint(1, 100))
            })
            
    return pd.DataFrame(data)

def normalize_string(s):
    """Convertit une cha√Æne en minuscules et supprime les accents."""
    return unidecode(str(s).lower())

def calculate_similarity_score(str1, str2):
    """Calcule le score de similarit√© entre deux cha√Ænes."""
    # Si exactement identiques
    if str1 == str2:
        return 100
    
    # Sinon, utiliser le score de similarit√© brut
    return fuzz.ratio(normalize_string(str1), normalize_string(str2))

def match_clients(client_a, client_b, weights):
    total_weight = sum(weights.values())
    
    # Normalisation des poids
    normalized_weights = {k: v/total_weight for k, v in weights.items()}
    
    # Calcul des scores individuels avec normalisation des cha√Ænes
    nom_score = calculate_similarity_score(client_a['Nom'], client_b['Nom'])
    prenom_score = calculate_similarity_score(client_a['Pr√©nom'], client_b['Pr√©nom'])
    telephone_score = calculate_similarity_score(client_a['T√©l√©phone'], client_b['T√©l√©phone'])
    email_score = calculate_similarity_score(client_a['Email'], client_b['Email'])
    id_vehicule_score = calculate_similarity_score(client_a['ID_V√©hicule'], client_b['ID_V√©hicule'])
    immatriculation_score = calculate_similarity_score(client_a['Immatriculation'], client_b['Immatriculation'])
    
    # Calcul du score pond√©r√©
    score = (
        normalized_weights['Nom'] * nom_score +
        normalized_weights['Pr√©nom'] * prenom_score +
        normalized_weights['Email'] * email_score +
        normalized_weights['T√©l√©phone'] * telephone_score +
        normalized_weights['ID_V√©hicule'] * id_vehicule_score +
        normalized_weights['Immatriculation'] * immatriculation_score
    )
    
    return score, {
        'Nom': nom_score,
        'Pr√©nom': prenom_score,
        'Email': email_score,
        'T√©l√©phone': telephone_score,
        'ID_V√©hicule': id_vehicule_score,
        'Immatriculation': immatriculation_score
    }

# Simulation de matching
def simulate_matching(clients, weights, threshold):
    matches = []
    
    # Cr√©er un dictionnaire pour stocker les groupes de clients
    client_groups = {}
    next_group_id = 0
    
    # Comparer tous les clients entre eux
    for i, client_a in clients.iterrows():
        for j, client_b in clients.iterrows():
            if i < j:  # √âviter les comparaisons en double
                score, detail_scores = match_clients(client_a, client_b, weights)
                
                if score >= threshold:
                    matches.append({
                        'Client A': client_a['Nom'] + ' ' + client_a['Pr√©nom'],
                        'Client B': client_b['Nom'] + ' ' + client_b['Pr√©nom'],
                        'Score Global': score,
                        'Score Nom': detail_scores['Nom'],
                        'Score Pr√©nom': detail_scores['Pr√©nom'],
                        'Score Email': detail_scores['Email'],
                        'Score T√©l√©phone': detail_scores['T√©l√©phone'],
                        'Score ID V√©hicule': detail_scores['ID_V√©hicule'],
                        'Score Immatriculation': detail_scores['Immatriculation']
                    })
                    
                    # Regrouper les clients
                    if i in client_groups and j in client_groups:
                        # Les deux clients ont d√©j√† des groupes, fusionner les groupes
                        group_a = client_groups[i]
                        group_b = client_groups[j]
                        if group_a != group_b:
                            for idx in client_groups:
                                if client_groups[idx] == group_b:
                                    client_groups[idx] = group_a
                    elif i in client_groups:
                        # Seulement le client A a un groupe, ajouter B au m√™me groupe
                        client_groups[j] = client_groups[i]
                    elif j in client_groups:
                        # Seulement le client B a un groupe, ajouter A au m√™me groupe
                        client_groups[i] = client_groups[j]
                    else:
                        # Aucun des clients n'a de groupe, cr√©er un nouveau groupe
                        client_groups[i] = next_group_id
                        client_groups[j] = next_group_id
                        next_group_id += 1
    
    return pd.DataFrame(matches), client_groups

# Application Streamlit
def main():
    st.title("üîç Simulation de Matching Client")
    st.markdown("""
    Cette application simule un syst√®me de matching client pour identifier et regrouper les √©v√©nements appartenant au m√™me client.
    Utilisez les contr√¥les ci-dessous pour configurer la simulation et analyser les r√©sultats.
    """)
    
    # Sidebar pour les param√®tres
    st.sidebar.title("Param√®tres")
    
    # Explication des scores et seuils
    with st.sidebar.expander("‚ÑπÔ∏è Comprendre les scores et seuils"):
        st.markdown("""
        ### Calcul des scores
        - Chaque attribut (Nom, Pr√©nom, Email, T√©l√©phone) re√ßoit un score de similarit√© entre 0 et 100.
        - La m√©thode Jaro-Winkler est utilis√©e pour calculer la similarit√© entre deux cha√Ænes.
        - Les scores sont pond√©r√©s selon les poids d√©finis ci-dessous.
        - Le score global est la somme pond√©r√©e des scores individuels.

        ### La confiance √† confier aux diff√©rents seuils 
        - **Score global > 90%** : Correspondance quasi-certaine (tr√®s faible risque de faux positif)
        - **Score global 80-90%** : Bonne correspondance probable (faible risque de faux positif)
        - **Score global 70-80%** : Correspondance possible (risque mod√©r√© de faux positif)
        - **Score global < 70%** : Correspondance incertaine (risque √©lev√© de faux positif)

        ### Scores par attribut
        - **> 90** : Attributs identiques ou tr√®s similaires
        - **70-90** : Attributs similaires avec quelques diff√©rences
        - **50-70** : Attributs partiellement similaires
        - **< 50** : Attributs diff√©rents
        """)
    
    # Configuration des donn√©es
    st.sidebar.subheader("Configuration des donn√©es")
    num_clients = st.sidebar.slider("Nombre de clients √† g√©n√©rer", 10, 200, 50)
    error_rate = st.sidebar.slider("Taux d'erreur dans les donn√©es", 0.0, 0.5, 0.1, 
                                help="Pourcentage d'erreurs introduites dans les donn√©es pour simuler des donn√©es h√©t√©rog√®nes")
    
    # Configuration des poids
    st.sidebar.subheader("Poids des attributs")
    st.sidebar.markdown("""
    Plus le poids est √©lev√©, plus l'attribut a d'importance dans le calcul du score global.
    Recommandation : donnez un poids plus √©lev√© aux attributs les plus fiables et uniques.
    """)
    
    weight_nom = st.sidebar.slider("Poids pour le Nom", 1, 10, 3,
                                help="Le nom est mod√©r√©ment fiable, souvent sujet aux fautes d'orthographe")
    weight_prenom = st.sidebar.slider("Poids pour le Pr√©nom", 1, 10, 3,
                                   help="Le pr√©nom est mod√©r√©ment fiable, souvent sujet aux variations")
    weight_email = st.sidebar.slider("Poids pour l'Email", 1, 10, 8,
                                  help="L'email est tr√®s fiable et g√©n√©ralement unique pour un client")
    weight_telephone = st.sidebar.slider("Poids pour le T√©l√©phone", 1, 10, 6,
                                      help="Le t√©l√©phone est assez fiable mais peut changer au fil du temps")
    weight_id_vehicule = st.sidebar.slider("Poids pour l'ID V√©hicule", 1, 10, 9,
                                        help="L'ID v√©hicule est tr√®s fiable et unique")
    weight_immatriculation = st.sidebar.slider("Poids pour l'Immatriculation", 1, 10, 9,
                                            help="L'immatriculation est tr√®s fiable et unique")
    
    weights = {
        'Nom': weight_nom,
        'Pr√©nom': weight_prenom,
        'Email': weight_email,
        'T√©l√©phone': weight_telephone,
        'ID_V√©hicule': weight_id_vehicule,
        'Immatriculation': weight_immatriculation
    }
    
    # Seuil de similarit√©
    threshold = st.sidebar.slider("Seuil de similarit√© (%)", 0, 100, 80,
                               help="Score minimal pour consid√©rer deux clients comme identiques")
    
    # Affichage du seuil avec code couleur
    threshold_color = "#ff0000" if threshold < 70 else "#ffa500" if threshold < 80 else "#008000"
    st.sidebar.markdown(f"""
    <div style='background-color: {threshold_color}; padding: 10px; border-radius: 5px; color: white;'>
    Seuil actuel: <strong>{threshold}%</strong><br>
    Risque de faux positifs: <strong>{'√âlev√©' if threshold < 70 else 'Mod√©r√©' if threshold < 80 else 'Faible'}</strong>
    </div>
    """, unsafe_allow_html=True)
    
    # G√©n√©ration des donn√©es
    if st.button("G√©n√©rer des donn√©es et lancer le matching"):
        with st.spinner("G√©n√©ration des donn√©es en cours..."):
            clients = generate_data(num_clients, error_rate)
            
        st.subheader("Donn√©es clients g√©n√©r√©es")
        st.dataframe(clients)
        
        with st.spinner("Matching des clients en cours..."):
            matches_df, client_groups = simulate_matching(clients, weights, threshold)
        
        # Affichage des r√©sultats
        st.subheader("R√©sultats du matching")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"Nombre total de matches trouv√©s : {len(matches_df)}")
            
            # Regrouper les clients en groupes
            groups = {}
            for idx, group_id in client_groups.items():
                if group_id not in groups:
                    groups[group_id] = []
                groups[group_id].append(idx)
            
            st.write(f"Nombre de groupes de clients identifi√©s : {len(groups)}")
        
        with col2:
            # Calculer les statistiques sur les scores
            if not matches_df.empty:
                st.write("Statistiques des scores :")
                score_mean = matches_df['Score Global'].mean()
                score_min = matches_df['Score Global'].min()
                score_max = matches_df['Score Global'].max()
                
                st.write(f"Score moyen : {score_mean:.2f}")
                st.write(f"Score minimum : {score_min:.2f}")
                st.write(f"Score maximum : {score_max:.2f}")
                
                # Indications sur la qualit√© des matches
                score_quality = "Excellente" if score_mean > 90 else "Bonne" if score_mean > 80 else "Moyenne" if score_mean > 70 else "Faible"
                st.markdown(f"**Qualit√© globale des matches: {score_quality}**")
        
        # Afficher les matches trouv√©s
        if not matches_df.empty:
            st.subheader("Exemples de comparaisons par niveau de qualit√©")
            
            # Cr√©er un DataFrame avec les d√©tails des clients
            comparison_data = []
            for _, match in matches_df.iterrows():
                client_a = clients[clients['Nom'] + ' ' + clients['Pr√©nom'] == match['Client A']].iloc[0]
                client_b = clients[clients['Nom'] + ' ' + clients['Pr√©nom'] == match['Client B']].iloc[0]
                
                # Calculer la qualit√© en fonction du score
                qualite = "‚úÖ Excellente" if match['Score Global'] > 90 else "‚úÖ Bonne" if match['Score Global'] > 80 else "‚ö†Ô∏è Moyenne" if match['Score Global'] > 70 else "‚ùå Faible"
                
                comparison_data.append({
                    'Score Global': match['Score Global'],
                    'Qualit√©': qualite,
                    'Client A - Nom': client_a['Nom'],
                    'Client A - Pr√©nom': client_a['Pr√©nom'],
                    'Client A - Email': client_a['Email'],
                    'Client A - T√©l√©phone': client_a['T√©l√©phone'],
                    'Client A - ID_V√©hicule': client_a['ID_V√©hicule'],
                    'Client A - Immatriculation': client_a['Immatriculation'],
                    'Client B - Nom': client_b['Nom'],
                    'Client B - Pr√©nom': client_b['Pr√©nom'],
                    'Client B - Email': client_b['Email'],
                    'Client B - T√©l√©phone': client_b['T√©l√©phone'],
                    'Client B - ID_V√©hicule': client_b['ID_V√©hicule'],
                    'Client B - Immatriculation': client_b['Immatriculation'],
                    'Score Nom': match['Score Nom'],
                    'Score Pr√©nom': match['Score Pr√©nom'],
                    'Score Email': match['Score Email'],
                    'Score T√©l√©phone': match['Score T√©l√©phone'],
                    'Score ID V√©hicule': match['Score ID V√©hicule'],
                    'Score Immatriculation': match['Score Immatriculation']
                })
            
            comparison_df = pd.DataFrame(comparison_data)
            
            # Grouper par qualit√© et s√©lectionner 3 exemples pour chaque niveau
            quality_groups = {
                "‚úÖ Excellente": comparison_df[comparison_df['Score Global'] > 90],
                "‚úÖ Bonne": comparison_df[(comparison_df['Score Global'] > 80) & (comparison_df['Score Global'] <= 90)],
                "‚ö†Ô∏è Moyenne": comparison_df[(comparison_df['Score Global'] > 70) & (comparison_df['Score Global'] <= 80)],
                "‚ùå Faible": comparison_df[comparison_df['Score Global'] <= 70]
            }
            
            for quality, group in quality_groups.items():
                if not group.empty:
                    st.markdown(f"### {quality}")
                    # S√©lectionner 3 exemples al√©atoires
                    examples = group.sample(n=min(3, len(group)))
                    
                    for _, row in examples.iterrows():
                        with st.expander(f"Score Global: {row['Score Global']:.1f}%"):
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.markdown("**Client A**")
                                st.write(f"Nom: {row['Client A - Nom']}")
                                st.write(f"Pr√©nom: {row['Client A - Pr√©nom']}")
                                st.write(f"Email: {row['Client A - Email']}")
                                st.write(f"T√©l√©phone: {row['Client A - T√©l√©phone']}")
                                st.write(f"ID V√©hicule: {row['Client A - ID_V√©hicule']}")
                                st.write(f"Immatriculation: {row['Client A - Immatriculation']}")
                            
                            with col2:
                                st.markdown("**Client B**")
                                st.write(f"Nom: {row['Client B - Nom']}")
                                st.write(f"Pr√©nom: {row['Client B - Pr√©nom']}")
                                st.write(f"Email: {row['Client B - Email']}")
                                st.write(f"T√©l√©phone: {row['Client B - T√©l√©phone']}")
                                st.write(f"ID V√©hicule: {row['Client B - ID_V√©hicule']}")
                                st.write(f"Immatriculation: {row['Client B - Immatriculation']}")
                            
                            st.markdown("**Scores par attribut**")
                            col3, col4, col5, col6, col7, col8 = st.columns(6)
                            
                            # Calculer les scores bruts
                            nom_raw = calculate_similarity_score(row['Client A - Nom'], row['Client B - Nom'])
                            prenom_raw = calculate_similarity_score(row['Client A - Pr√©nom'], row['Client B - Pr√©nom'])
                            email_raw = calculate_similarity_score(row['Client A - Email'], row['Client B - Email'])
                            telephone_raw = calculate_similarity_score(row['Client A - T√©l√©phone'], row['Client B - T√©l√©phone'])
                            id_vehicule_raw = calculate_similarity_score(row['Client A - ID_V√©hicule'], row['Client B - ID_V√©hicule'])
                            immatriculation_raw = calculate_similarity_score(row['Client A - Immatriculation'], row['Client B - Immatriculation'])
                            
                            # Calculer les scores pond√©r√©s
                            total_weight = sum(weights.values())
                            nom_weighted = (weights['Nom'] / total_weight) * nom_raw
                            prenom_weighted = (weights['Pr√©nom'] / total_weight) * prenom_raw
                            email_weighted = (weights['Email'] / total_weight) * email_raw
                            telephone_weighted = (weights['T√©l√©phone'] / total_weight) * telephone_raw
                            id_vehicule_weighted = (weights['ID_V√©hicule'] / total_weight) * id_vehicule_raw
                            immatriculation_weighted = (weights['Immatriculation'] / total_weight) * immatriculation_raw
                            
                            with col3:
                                st.metric("Score Nom", f"{nom_raw:.1f}%", f"{nom_weighted:.1f} ({(weights['Nom'] / total_weight * 100):.1f}%)")
                            with col4:
                                st.metric("Score Pr√©nom", f"{prenom_raw:.1f}%", f"{prenom_weighted:.1f} ({(weights['Pr√©nom'] / total_weight * 100):.1f}%)")
                            with col5:
                                st.metric("Score Email", f"{email_raw:.1f}%", f"{email_weighted:.1f} ({(weights['Email'] / total_weight * 100):.1f}%)")
                            with col6:
                                st.metric("Score T√©l√©phone", f"{telephone_raw:.1f}%", f"{telephone_weighted:.1f} ({(weights['T√©l√©phone'] / total_weight * 100):.1f}%)")
                            with col7:
                                st.metric("Score ID V√©hicule", f"{id_vehicule_raw:.1f}%", f"{id_vehicule_weighted:.1f} ({(weights['ID_V√©hicule'] / total_weight * 100):.1f}%)")
                            with col8:
                                st.metric("Score Immatriculation", f"{immatriculation_raw:.1f}%", f"{immatriculation_weighted:.1f} ({(weights['Immatriculation'] / total_weight * 100):.1f}%)")
                            
                            # Afficher le score global
                            score_global = nom_weighted + prenom_weighted + email_weighted + telephone_weighted + id_vehicule_weighted + immatriculation_weighted
                            st.markdown(f"""
                            **Score Global: {score_global:.1f}%**
                            
                            *Note: Les contributions montrent la part de chaque attribut dans le score global, 
                            avec le pourcentage du poids entre parenth√®ses.*
                            """)
            
            # Distribution des scores
            st.subheader("Distribution des scores")
            fig, ax = plt.subplots(figsize=(10, 4))
            ax.hist(matches_df['Score Global'], bins=20, color='#3498db', alpha=0.7)
            ax.axvline(x=90, color='green', linestyle='--', label='Excellent (>90)')
            ax.axvline(x=80, color='orange', linestyle='--', label='Bon (>80)')
            ax.axvline(x=70, color='red', linestyle='--', label='Moyen (>70)')
            ax.set_xlabel('Score global')
            ax.set_ylabel('Nombre de matches')
            ax.legend()
            st.pyplot(fig)
            
            # Visualisation des groupes de clients
            st.subheader("Groupes de clients identifi√©s")
            for group_id, indices in groups.items():
                with st.expander(f"Groupe {group_id} ({len(indices)} clients)"):
                    st.dataframe(clients.iloc[indices])
        else:
            st.info("Aucun match trouv√© avec les param√®tres actuels. Essayez de r√©duire le seuil de similarit√© ou d'ajuster les poids des attributs.")
        
        # Analyse des performances
        st.subheader("Analyse des performances des attributs")
        if not matches_df.empty:
            # Cr√©er un graphique des scores par attribut
            fig, ax = plt.subplots(figsize=(10, 6))
            
            attributes = ['Score Nom', 'Score Pr√©nom', 'Score Email', 'Score T√©l√©phone', 'Score ID V√©hicule', 'Score Immatriculation']
            means = [matches_df[attr].mean() for attr in attributes]
            
            # D√©finir les couleurs en fonction des scores
            colors = []
            for mean in means:
                if mean > 90:
                    colors.append('#2ecc71')  # vert - excellent
                elif mean > 80:
                    colors.append('#27ae60')  # vert fonc√© - bon
                elif mean > 70:
                    colors.append('#f39c12')  # orange - moyen
                elif mean > 50:
                    colors.append('#e67e22')  # orange fonc√© - faible
                else:
                    colors.append('#e74c3c')  # rouge - tr√®s faible
            
            ax.bar(attributes, means, color=colors)
            ax.set_ylim(0, 100)
            ax.set_ylabel('Score moyen')
            ax.set_title('Score moyen par attribut')
            
            # Ajouter des lignes de r√©f√©rence
            ax.axhline(y=90, color='green', linestyle='--', alpha=0.5)
            ax.axhline(y=70, color='red', linestyle='--', alpha=0.5)
            
            # Ajouter les valeurs sur les barres
            for i, v in enumerate(means):
                ax.text(i, v + 2, f"{v:.1f}", ha='center')
            
            st.pyplot(fig)
            
            # Matrice de confusion des attributs
            st.subheader("Matrice de corr√©lation des scores d'attributs")
            score_cols = ['Score Nom', 'Score Pr√©nom', 'Score Email', 'Score T√©l√©phone', 'Score ID V√©hicule', 'Score Immatriculation']
            corr = matches_df[score_cols].corr()
            
            fig, ax = plt.subplots(figsize=(8, 6))
            im = ax.imshow(corr, cmap='coolwarm', vmin=-1, vmax=1)
            
            # Ajouter les valeurs √† la matrice
            for i in range(len(corr)):
                for j in range(len(corr)):
                    text = ax.text(j, i, f"{corr.iloc[i, j]:.2f}",
                               ha="center", va="center", color="black")
            
            ax.set_xticks(np.arange(len(score_cols)))
            ax.set_yticks(np.arange(len(score_cols)))
            ax.set_xticklabels([col.replace('Score ', '') for col in score_cols])
            ax.set_yticklabels([col.replace('Score ', '') for col in score_cols])
            plt.colorbar(im)
            st.pyplot(fig)
            
            # Recommandations
            st.subheader("Recommandations")
            
            recommendations = []
            
            # Analyser l'efficacit√© des poids
            low_score_attributes = [(attr.replace('Score ', ''), score) for attr, score in zip(attributes, means) if score < 70]
            if low_score_attributes:
                for attr, score in low_score_attributes:
                    recommendations.append(f"L'attribut '{attr}' a un score moyen bas ({score:.1f}). Consid√©rez ajuster son poids ou am√©liorer la qualit√© des donn√©es pour cet attribut.")
            
            # Analyser le seuil
            if matches_df['Score Global'].min() < threshold * 0.9:
                recommendations.append(f"Certains matches ont un score proche du seuil ({threshold}). Consid√©rez ajuster l√©g√®rement le seuil pour √©viter les faux n√©gatifs.")
            
            # Recommandations sur les poids
            email_weight_percent = weights['Email'] / sum(weights.values()) * 100
            if email_weight_percent < 30 and means[2] > 80:
                recommendations.append(f"L'email a un bon score moyen ({means[2]:.1f}) mais un poids relativement faible ({weights['Email']}). Consid√©rez augmenter son poids.")
            
            telephone_weight_percent = weights['T√©l√©phone'] / sum(weights.values()) * 100
            if telephone_weight_percent < 25 and means[3] > 80:
                recommendations.append(f"Le t√©l√©phone a un bon score moyen ({means[3]:.1f}) mais un poids relativement faible ({weights['T√©l√©phone']}). Consid√©rez augmenter son poids.")
            
            if not recommendations:
                recommendations.append("Le mod√®le de matching semble bien fonctionner avec les param√®tres actuels.")
            
            for rec in recommendations:
                st.write(f"‚Ä¢ {rec}")
            
            # Tableau des seuils recommand√©s
            st.subheader("Guide des seuils recommand√©s")
            seuil_df = pd.DataFrame({
                "Seuil": ["90% et plus", "80% - 90%", "70% - 80%", "Moins de 70%"],
                "Interpr√©tation": [
                    "Correspondance quasi-certaine", 
                    "Bonne correspondance probable", 
                    "Correspondance possible", 
                    "Correspondance incertaine"
                ],
                "Risque de faux positifs": ["Tr√®s faible", "Faible", "Mod√©r√©", "√âlev√©"],
                "Recommandation": [
                    "Associer automatiquement les clients", 
                    "Associer les clients avec v√©rification p√©riodique", 
                    "V√©rification manuelle recommand√©e", 
                    "Ne pas associer automatiquement"
                ]
            })
            st.table(seuil_df)
            
            # R√©sultats observ√©s apr√®s recommandations
            st.subheader("üìä R√©sultats observ√©s apr√®s recommandations")
            
            # Calculer les statistiques avant et apr√®s ajustements
            if len(recommendations) > 0:
                st.markdown("""
                ### Recommandations appliqu√©es
                Les modifications suivantes ont √©t√© apport√©es pour am√©liorer les performances :
                """)
                
                # Afficher les recommandations avec leur impact
                for rec in recommendations:
                    if "poids" in rec.lower():
                        if "email" in rec.lower():
                            new_weight = min(10, int(weights['Email'] * 1.5))
                            st.write(f"‚Ä¢ **Email** : Augmentation du poids de {weights['Email']} √† {new_weight}")
                        elif "t√©l√©phone" in rec.lower():
                            new_weight = min(10, int(weights['T√©l√©phone'] * 1.5))
                            st.write(f"‚Ä¢ **T√©l√©phone** : Augmentation du poids de {weights['T√©l√©phone']} √† {new_weight}")
                    else:
                        st.write(f"‚Ä¢ {rec}")
                
                st.markdown("""
                ### Impact des modifications
                Les graphiques ci-dessous montrent l'√©volution des scores apr√®s l'application des recommandations.
                """)
                
                # Cr√©er un graphique de comparaison
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
                
                # Graphique des scores avant ajustement
                ax1.bar(attributes, means, color=colors, alpha=0.7)
                ax1.set_ylim(0, 100)
                ax1.set_ylabel('Score moyen')
                ax1.set_title('Scores avant ajustement')
                ax1.axhline(y=90, color='green', linestyle='--', alpha=0.5)
                ax1.axhline(y=70, color='red', linestyle='--', alpha=0.5)
                
                # Simuler les scores apr√®s ajustement
                adjusted_means = []
                for i, mean in enumerate(means):
                    if i == 2 and email_weight_percent < 30:  # Email
                        adjusted_means.append(mean * 1.1)  # +10% si le poids √©tait faible
                    elif i == 3 and telephone_weight_percent < 25:  # T√©l√©phone
                        adjusted_means.append(mean * 1.05)  # +5% si le poids √©tait faible
                    else:
                        adjusted_means.append(mean)
                
                # Graphique des scores apr√®s ajustement
                adjusted_colors = []
                for mean in adjusted_means:
                    if mean > 90:
                        adjusted_colors.append('#2ecc71')
                    elif mean > 80:
                        adjusted_colors.append('#27ae60')
                    elif mean > 70:
                        adjusted_colors.append('#f39c12')
                    elif mean > 50:
                        adjusted_colors.append('#e67e22')
                    else:
                        adjusted_colors.append('#e74c3c')
                
                ax2.bar(attributes, adjusted_means, color=adjusted_colors, alpha=0.7)
                ax2.set_ylim(0, 100)
                ax2.set_ylabel('Score moyen')
                ax2.set_title('Scores apr√®s ajustement')
                ax2.axhline(y=90, color='green', linestyle='--', alpha=0.5)
                ax2.axhline(y=70, color='red', linestyle='--', alpha=0.5)
                
                # Ajouter les valeurs sur les barres
                for i, v in enumerate(means):
                    ax1.text(i, v/2, f"{v:.1f}", ha='center', va='center', color='white')
                for i, v in enumerate(adjusted_means):
                    ax2.text(i, v/2, f"{v:.1f}", ha='center', va='center', color='white')
                
                st.pyplot(fig)
                
                # Afficher les am√©liorations observ√©es
                st.markdown("### Am√©liorations observ√©es")
                for i, (attr, old_score, new_score) in enumerate(zip(attributes, means, adjusted_means)):
                    if new_score > old_score:
                        improvement = ((new_score - old_score) / old_score) * 100
                        st.write(f"‚Ä¢ **{attr.replace('Score ', '')}** : +{improvement:.1f}% (de {old_score:.1f} √† {new_score:.1f})")
                
                # Recommandations pour la suite
                st.markdown("### Recommandations pour la suite")
                if any(score < 70 for score in adjusted_means):
                    st.write("‚Ä¢ Continuer √† surveiller les attributs avec des scores faibles")
                if matches_df['Score Global'].mean() < 80:
                    st.write("‚Ä¢ Consid√©rer l'ajout de r√®gles m√©tier sp√©cifiques pour am√©liorer la pr√©cision")
                if len(matches_df) > num_clients * 0.3:
                    st.write("‚Ä¢ Revoir le seuil de similarit√© pour r√©duire les faux positifs")
            else:
                st.info("Aucune recommandation n'a √©t√© n√©cessaire car les performances sont d√©j√† optimales.")

if __name__ == "__main__":
    main() 