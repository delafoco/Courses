import streamlit as st
import pandas as pd
import numpy as np
from fuzzywuzzy import fuzz
from unidecode import unidecode
import matplotlib.pyplot as plt
import random

# Configuration de la page Streamlit
st.set_page_config(
    page_title="Simulation de Matching Client",
    page_icon="üîç",
    layout="wide"
)

# Fonction de g√©n√©ration de donn√©es
def generate_data(num_clients, error_rate=0.1):
    data = []
    
    # Liste plus large de noms et pr√©noms pour plus de variations
    noms = ["Martin", "Dubois", "Thomas", "Richard", "Petit", "Durand", "Leroy", "Moreau", "Simon", "Laurent",
            "Bernard", "Robert", "Michel", "Garcia", "David", "Bertrand", "Roux", "Vincent", "Fournier", "Morel"]
    prenoms = ["Jean", "Marie", "Pierre", "Michel", "Sophie", "Catherine", "Nicolas", "Isabelle", "Philippe", "Anne",
               "Claude", "Lucas", "Emma", "L√©a", "Hugo", "Louis", "Jules", "Alice", "Lina", "Noah"]
    
    for i in range(num_clients):
        nom = noms[i % len(noms)]
        prenom = prenoms[i % len(prenoms)]
        id_vehicule = f"VEH{i:05d}"
        immatriculation = f"AB-{i%999:03d}-CD"
        email = f"{prenom.lower()}.{nom.lower()}@example.com"
        telephone = f"01{i%99:02d}345678"
        
        # Introduire des erreurs al√©atoires pour simuler des donn√©es h√©t√©rog√®nes
        if np.random.rand() < error_rate:
            # Erreurs plus vari√©es dans le nom
            error_type = np.random.choice(['suppression', 'ajout', 'substitution', 'inversion'])
            if error_type == 'suppression':
                nom = nom[:-1] if len(nom) > 3 else nom
            elif error_type == 'ajout':
                nom = nom + ('e' if nom[-1] != 'e' else 'a')
            elif error_type == 'substitution':
                pos = np.random.randint(0, len(nom))
                nom = nom[:pos] + ('e' if nom[pos] != 'e' else 'a') + nom[pos+1:]
            else:  # inversion
                if len(nom) > 3:
                    pos = np.random.randint(0, len(nom)-1)
                    nom = nom[:pos] + nom[pos+1] + nom[pos] + nom[pos+2:]
        
        if np.random.rand() < error_rate:
            # Erreurs plus vari√©es dans le pr√©nom
            error_type = np.random.choice(['suppression', 'ajout', 'substitution', 'inversion'])
            if error_type == 'suppression':
                prenom = prenom[:-1] if len(prenom) > 3 else prenom
            elif error_type == 'ajout':
                prenom = prenom + ('s' if prenom[-1] != 's' else 'e')
            elif error_type == 'substitution':
                pos = np.random.randint(0, len(prenom))
                prenom = prenom[:pos] + ('e' if prenom[pos] != 'e' else 'a') + prenom[pos+1:]
            else:  # inversion
                if len(prenom) > 3:
                    pos = np.random.randint(0, len(prenom)-1)
                    prenom = prenom[:pos] + prenom[pos+1] + prenom[pos] + prenom[pos+2:]
        
        if np.random.rand() < error_rate:
            # Erreurs plus vari√©es dans l'email
            error_type = np.random.choice(['domaine', 'format', 'caract√®res'])
            if error_type == 'domaine':
                email = email.replace('@example.com', '@gmail.com')
            elif error_type == 'format':
                email = email.replace('.', '_')
            else:  # caract√®res
                email = email.replace('a', '4').replace('e', '3').replace('i', '1').replace('o', '0')
        
        if np.random.rand() < error_rate:
            # Erreurs plus vari√©es dans le t√©l√©phone
            error_type = np.random.choice(['format', 'chiffres', 'longueur'])
            if error_type == 'format':
                telephone = telephone.replace('-', ' ').replace(' ', '')
            elif error_type == 'chiffres':
                pos = np.random.randint(0, len(telephone))
                telephone = telephone[:pos] + str(np.random.randint(0, 10)) + telephone[pos+1:]
            else:  # longueur
                if np.random.rand() < 0.5:
                    telephone = telephone[:-1]  # trop court
                else:
                    telephone = telephone + str(np.random.randint(0, 10))  # trop long
        
        # Ajouter des erreurs dans l'ID v√©hicule
        if np.random.rand() < error_rate:
            error_type = np.random.choice(['chiffres', 'format', 'longueur'])
            if error_type == 'chiffres':
                pos = np.random.randint(3, len(id_vehicule))
                id_vehicule = id_vehicule[:pos] + str(np.random.randint(0, 10)) + id_vehicule[pos+1:]
            elif error_type == 'format':
                id_vehicule = id_vehicule.replace('VEH', 'VH')
            else:  # longueur
                if np.random.rand() < 0.5:
                    id_vehicule = id_vehicule[:-1]  # trop court
                else:
                    id_vehicule = id_vehicule + str(np.random.randint(0, 10))  # trop long
        
        # Ajouter des erreurs dans l'immatriculation
        if np.random.rand() < error_rate:
            error_type = np.random.choice(['chiffres', 'format', 'lettres'])
            if error_type == 'chiffres':
                pos = np.random.randint(3, 6)
                immatriculation = immatriculation[:pos] + str(np.random.randint(0, 10)) + immatriculation[pos+1:]
            elif error_type == 'format':
                immatriculation = immatriculation.replace('-', ' ')
            else:  # lettres
                pos = np.random.randint(0, 2)
                immatriculation = immatriculation[:pos] + chr(np.random.randint(65, 91)) + immatriculation[pos+1:]
        
        data.append({
            'Nom': nom,
            'Pr√©nom': prenom,
            'ID_V√©hicule': id_vehicule,
            'Immatriculation': immatriculation,
            'Email': email,
            'T√©l√©phone': telephone,
            'Date': pd.Timestamp.now() - pd.Timedelta(days=np.random.randint(1, 100))
        })
        
        # Ajouter des doublons avec des variations plus importantes
        if i % 5 == 0:
            nom_alt = nom
            prenom_alt = prenom
            email_alt = email
            telephone_alt = telephone
            id_vehicule_alt = id_vehicule
            immatriculation_alt = immatriculation
            
            # Variations plus importantes pour les doublons
            if np.random.rand() < 0.3:
                nom_alt = nom.upper()
            if np.random.rand() < 0.3:
                prenom_alt = prenom.upper()
            if np.random.rand() < 0.3:
                # Variations d'email plus importantes
                email_variations = [
                    email.replace('@example.com', '@gmail.com'),
                    email.replace('.', '_'),
                    email.replace('a', '4').replace('e', '3').replace('i', '1').replace('o', '0'),
                    f"{prenom.lower()}{nom.lower()}@example.com",
                    f"{nom.lower()}.{prenom.lower()}@example.com"
                ]
                email_alt = np.random.choice(email_variations)
            if np.random.rand() < 0.3:
                # Variations de t√©l√©phone plus importantes
                telephone_variations = [
                    telephone.replace('-', ' ').replace(' ', ''),
                    telephone.replace('01', '06'),
                    telephone.replace('01', '07'),
                    telephone[:-1] + str(np.random.randint(0, 10)),
                    telephone + str(np.random.randint(0, 10))
                ]
                telephone_alt = np.random.choice(telephone_variations)
            if np.random.rand() < 0.3:
                # Variations d'ID v√©hicule plus importantes
                id_vehicule_variations = [
                    id_vehicule.replace('VEH', 'VH'),
                    id_vehicule.replace('VEH', 'VEH-'),
                    id_vehicule[:-1] + str(np.random.randint(0, 10)),
                    id_vehicule + str(np.random.randint(0, 10))
                ]
                id_vehicule_alt = np.random.choice(id_vehicule_variations)
            if np.random.rand() < 0.3:
                # Variations d'immatriculation plus importantes
                immatriculation_variations = [
                    immatriculation.replace('-', ' '),
                    immatriculation.replace('AB', 'BA'),
                    immatriculation.replace('CD', 'DC'),
                    immatriculation.replace('-', '')
                ]
                immatriculation_alt = np.random.choice(immatriculation_variations)
                
            data.append({
                'Nom': nom_alt,
                'Pr√©nom': prenom_alt,
                'ID_V√©hicule': id_vehicule_alt,
                'Immatriculation': immatriculation_alt,
                'Email': email_alt,
                'T√©l√©phone': telephone_alt,
                'Date': pd.Timestamp.now() - pd.Timedelta(days=np.random.randint(1, 100))
            })
            
    return pd.DataFrame(data)

def normalize_string(s):
    """Convertit une cha√Æne en minuscules et supprime les accents."""
    return unidecode(str(s).lower())

def calculate_similarity(str1, str2):
    """Calcule la similarit√© entre deux cha√Ænes en utilisant Jaro-Winkler"""
    return fuzz.ratio(normalize_string(str1), normalize_string(str2)) / 100

def match_clients(client_a, client_b, weights):
    """Calcule le score de matching entre deux clients en appliquant les poids uniquement au score final"""
    # Calcul des scores individuels avec Jaro-Winkler (sans poids)
    nom_score = calculate_similarity(client_a['Nom'], client_b['Nom'])
    prenom_score = calculate_similarity(client_a['Pr√©nom'], client_b['Pr√©nom'])
    telephone_score = calculate_similarity(client_a['T√©l√©phone'], client_b['T√©l√©phone'])
    email_score = calculate_similarity(client_a['Email'], client_b['Email'])
    id_vehicule_score = calculate_similarity(client_a['ID_V√©hicule'], client_b['ID_V√©hicule'])
    immatriculation_score = calculate_similarity(client_a['Immatriculation'], client_b['Immatriculation'])
    
    # Normalisation des poids pour le score final
    total_weight = sum(weights.values())
    normalized_weights = {k: v/total_weight for k, v in weights.items()}
    
    # Calcul du score final pond√©r√©
    score = (
        normalized_weights['Nom'] * nom_score +
        normalized_weights['Pr√©nom'] * prenom_score +
        normalized_weights['Email'] * email_score +
        normalized_weights['T√©l√©phone'] * telephone_score +
        normalized_weights['ID_V√©hicule'] * id_vehicule_score +
        normalized_weights['Immatriculation'] * immatriculation_score
    )
    
    return score, {
        'Nom': nom_score,
        'Pr√©nom': prenom_score,
        'Email': email_score,
        'T√©l√©phone': telephone_score,
        'ID_V√©hicule': id_vehicule_score,
        'Immatriculation': immatriculation_score
    }

def match_clients_advanced(client_a, client_b, weights):
    """
    Algorithme de matching avanc√© avec validation crois√©e
    """
    # 1. Calcul des scores individuels avec Jaro-Winkler (sans poids)
    scores = {}
    for attr in ['Nom', 'Pr√©nom', 'Email', 'T√©l√©phone', 'ID_V√©hicule', 'Immatriculation']:
        scores[attr] = calculate_similarity(client_a[attr], client_b[attr])
    
    # 2. Validation des attributs critiques
    critical_attrs = ['ID_V√©hicule', 'Immatriculation']
    critical_match = all(scores[attr] > 0.9 for attr in critical_attrs)
    
    # 3. Validation des attributs secondaires
    secondary_attrs = ['Email', 'T√©l√©phone']
    secondary_match = sum(scores[attr] > 0.85 for attr in secondary_attrs) >= 1
    
    # 4. Validation des attributs nominaux
    nominal_attrs = ['Nom', 'Pr√©nom']
    nominal_match = all(scores[attr] > 0.8 for attr in nominal_attrs)
    
    # 5. Calcul du score final pond√©r√©
    total_weight = sum(weights.values())
    normalized_weights = {k: v/total_weight for k, v in weights.items()}
    global_score = sum(scores[attr] * normalized_weights[attr] for attr in scores)
    
    # 6. R√®gles de d√©cision
    if critical_match:
        return global_score, scores, "FUSION_AUTOMATIQUE"
    elif global_score > 0.85 and secondary_match:
        return global_score, scores, "FUSION_VERIFICATION"
    elif global_score > 0.75 and nominal_match:
        return global_score, scores, "FUSION_VALIDATION"
    else:
        return global_score, scores, "PAS_FUSION"

def simulate_matching(clients, weights, threshold):
    matches = []
    
    # Cr√©er un dictionnaire pour stocker les groupes de clients
    client_groups = {}
    next_group_id = 0
    
    # Comparer tous les clients entre eux
    for i, client_a in clients.iterrows():
        for j, client_b in clients.iterrows():
            if i < j:  # √âviter les comparaisons en double
                score, detail_scores = match_clients(client_a, client_b, weights)
                
                if score >= threshold:
                    matches.append({
                        'Client A': client_a['Nom'] + ' ' + client_a['Pr√©nom'],
                        'Client B': client_b['Nom'] + ' ' + client_b['Pr√©nom'],
                        'Score Global': score,
                        'Score Nom': detail_scores['Nom'],
                        'Score Pr√©nom': detail_scores['Pr√©nom'],
                        'Score Email': detail_scores['Email'],
                        'Score T√©l√©phone': detail_scores['T√©l√©phone'],
                        'Score ID V√©hicule': detail_scores['ID_V√©hicule'],
                        'Score Immatriculation': detail_scores['Immatriculation']
                    })
                    
                    # Regrouper les clients
                    if i in client_groups and j in client_groups:
                        # Les deux clients ont d√©j√† des groupes, fusionner les groupes
                        group_a = client_groups[i]
                        group_b = client_groups[j]
                        if group_a != group_b:
                            for idx in client_groups:
                                if client_groups[idx] == group_b:
                                    client_groups[idx] = group_a
                    elif i in client_groups:
                        # Seulement le client A a un groupe, ajouter B au m√™me groupe
                        client_groups[j] = client_groups[i]
                    elif j in client_groups:
                        # Seulement le client B a un groupe, ajouter A au m√™me groupe
                        client_groups[i] = client_groups[j]
                    else:
                        # Aucun des clients n'a de groupe, cr√©er un nouveau groupe
                        client_groups[i] = next_group_id
                        client_groups[j] = next_group_id
                        next_group_id += 1
    
    return pd.DataFrame(matches), client_groups

def simulate_matching_advanced(clients, weights, threshold):
    """
    Simulation de matching avec l'algorithme avanc√©
    """
    matches = []
    client_groups = {}
    next_group_id = 0
    
    for i, client_a in clients.iterrows():
        for j, client_b in clients.iterrows():
            if i < j:
                score, detail_scores, decision = match_clients_advanced(client_a, client_b, weights)
                
                if decision != "PAS_FUSION":
                    matches.append({
                        'Client A': client_a['Nom'] + ' ' + client_a['Pr√©nom'],
                        'Client B': client_b['Nom'] + ' ' + client_b['Pr√©nom'],
                        'Score Global': score,
                        'D√©cision': decision,
                        'Score Nom': detail_scores['Nom'],
                        'Score Pr√©nom': detail_scores['Pr√©nom'],
                        'Score Email': detail_scores['Email'],
                        'Score T√©l√©phone': detail_scores['T√©l√©phone'],
                        'Score ID V√©hicule': detail_scores['ID_V√©hicule'],
                        'Score Immatriculation': detail_scores['Immatriculation']
                    })
                    
                    # Logique de groupement adapt√©e √† la d√©cision
                    if decision == "FUSION_AUTOMATIQUE":
                        # Fusion imm√©diate
                        if i in client_groups and j in client_groups:
                            group_a = client_groups[i]
                            group_b = client_groups[j]
                            if group_a != group_b:
                                for idx in client_groups:
                                    if client_groups[idx] == group_b:
                                        client_groups[idx] = group_a
                        elif i in client_groups:
                            client_groups[j] = client_groups[i]
                        elif j in client_groups:
                            client_groups[i] = client_groups[j]
                        else:
                            client_groups[i] = next_group_id
                            client_groups[j] = next_group_id
                            next_group_id += 1
                    else:
                        # Pour les autres d√©cisions, on cr√©e des groupes s√©par√©s
                        if i not in client_groups:
                            client_groups[i] = next_group_id
                            next_group_id += 1
                        if j not in client_groups:
                            client_groups[j] = next_group_id
                            next_group_id += 1
    
    return pd.DataFrame(matches), client_groups

# Application Streamlit
def main():
    """
    Application principale de matching client
    Version 1.0 - Support de GitLab et GitHub
    """
    st.title("üîç Simulation de Matching Client")
    
    # Introduction d√©taill√©e
    st.markdown("""
    ## √âtude de Cas : Vision Client Unifi√©e
    
    ### Contexte Business
    Des donn√©es clients sont collect√©es via diff√©rents canaux.
    
    Chaque interaction cr√©e un nouvel √©v√©nement dans la base de donn√©es.

    **Objectif** : Cr√©er une vision unifi√©e du client en rapprochant les √©v√©nements des diff√©rents canaux pour une m√™me personne.
    
    **Donn√©es** : 6 attributs cl√©s pour identifier un client :
    1. Nom
    2. Pr√©nom
    3. ID V√©hicule
    4. Immatriculation
    5. Email
    6. T√©l√©phone
    
    **Contraintes** :
    - Qualit√© h√©t√©rog√®ne des donn√©es selon les canaux
    - Risque de faux positifs (fusionner deux clients diff√©rents)
    - Risque de faux n√©gatifs (ne pas fusionner le m√™me client)
    
    ### Algorithme de Matching
    
    #### 1. Algorithme de Base : Jaro-Winkler
   
    - Utilise l'algorithme Jaro-Winkler pour calculer la similarit√© entre cha√Ænes
    - Normalise les cha√Ænes (suppression accents, majuscules)
    - Calcule un score de similarit√© brut entre 0 et 1

    **Description rapide de Jaro-Winkler :**
    - Algorithme de similarit√© entre cha√Ænes de caract√®res
    - Prend en compte les caract√®res communs et leur position
    - Score plus √©lev√© si les caract√®res communs sont au d√©but
    - Id√©al pour les noms, pr√©noms et textes courts
    - G√®re bien les erreurs de frappe et les variations mineures
    - Score de 1.0 = cha√Ænes identiques
    - Score de 0.0 = cha√Ænes compl√®tement diff√©rentes
    
    #### 2. Algorithme de Matching Avanc√©
    - Calcul des scores individuels avec Jaro-Winkler
    - Validation des attributs critiques (ID V√©hicule, Immatriculation)
    - Validation des attributs secondaires (Email, T√©l√©phone)
    - Validation des attributs nominaux (Nom, Pr√©nom)
    
    #### 3. R√®gles de D√©cision Hi√©rarchiques
    1. **Approche Multi-niveaux**
       - Validation des attributs critiques (ID V√©hicule, Immatriculation)
       - Validation des attributs secondaires (Email, T√©l√©phone)
       - Validation des attributs nominaux (Nom, Pr√©nom)
    
    2. **Syst√®me de Poids**
       - Poids par attribut (0.0 √† 1.0) pour le score final
       - Normalisation des poids
       - Influence sur la d√©cision finale uniquement
    
    3. **R√®gles de Fusion**
       - Fusion automatique (score > 90%)
       - Fusion avec v√©rification (score 80-90%)
       - Fusion avec validation (score 70-80%)
       - Pas de fusion (< 70%)
    
    4. **Validation Crois√©e**
       - V√©rification de la coh√©rence des dates
       - Analyse des patterns d'utilisation
       - D√©tection des anomalies
    
    ### M√©triques de Performance
    - **Pr√©cision** : √âviter les faux positifs (fusionner deux clients diff√©rents)
    - **Rappel** : √âviter les faux n√©gatifs (ne pas fusionner le m√™me client)
    - **Score F1** : √âquilibre entre pr√©cision et rappel
    
    Utilisez les contr√¥les ci-dessous pour simuler et analyser diff√©rentes configurations.
    """)
    
    # Sidebar pour les param√®tres
    st.sidebar.title("Param√®tres")
    
    # Explication des scores et seuils
    with st.sidebar.expander("‚ÑπÔ∏è Comprendre les scores et seuils"):
        st.markdown("""
        ### Strat√©gie de Matching
        Pour minimiser les erreurs critiques :
        
        1. **Privil√©gier la Pr√©cision**
           - Seuil √©lev√© pour les attributs critiques (ID V√©hicule, Immatriculation)
           - V√©rification crois√©e entre attributs
        
        2. **Gestion des Risques**
           - Faux Positifs : Risque de fusionner deux clients diff√©rents
           - Faux N√©gatifs : Risque de ne pas fusionner le m√™me client
        
        3. **Poids des Attributs**
           - ID V√©hicule & Immatriculation (0.9) : Tr√®s fiables, uniques
           - Email (0.8) : Tr√®s fiable, personnel
           - T√©l√©phone (0.7) : Assez fiable, peut changer
           - Nom & Pr√©nom (0.5) : Moins fiables, sujets aux erreurs
        
        ### Seuils Recommand√©s
        - **> 90%** : Fusion automatique (tr√®s faible risque de faux positif)
        - **80-90%** : Fusion avec v√©rification (faible risque)
        - **70-80%** : V√©rification manuelle requise (risque mod√©r√©)
        - **< 70%** : Pas de fusion (risque √©lev√©)
        """)
    
    # Configuration des donn√©es
    st.sidebar.subheader("Configuration des donn√©es")
    num_clients = st.sidebar.slider("Nombre de clients √† g√©n√©rer", 10, 200, 50)
    error_rate = st.sidebar.slider("Taux d'erreur dans les donn√©es", 0.0, 0.5, 0.1, 
                                help="Pourcentage d'erreurs introduites dans les donn√©es pour simuler des donn√©es h√©t√©rog√®nes")
    
    # Configuration des poids
    st.sidebar.markdown("### Poids des attributs (facteurs d'importance)")
    st.sidebar.markdown("""
    Les poids sont utilis√©s uniquement pour le calcul du score final :
    - 1.0 = importance maximale
    - 0.5 = importance moyenne
    - 0.0 = importance minimale

    **Recommandations par d√©faut :**
    - ID V√©hicule & Immatriculation (0.9) : Tr√®s fiables, uniques
    - Email (0.8) : Tr√®s fiable, personnel
    - T√©l√©phone (0.7) : Assez fiable, peut changer
    - Nom & Pr√©nom (0.5) : Moins fiables, sujets aux erreurs

    Note : Les poids n'affectent que le score final. Le calcul de similarit√© Jaro-Winkler est effectu√© sans poids.
    """)
    
    weights = {
        'Nom': st.sidebar.slider('Poids du nom', 0.0, 1.0, 0.5, 0.1,
                                help="Importance du nom dans le score final (0 = minimal, 1 = maximal). Recommand√© : 0.5 car sujet aux erreurs."),
        'Pr√©nom': st.sidebar.slider('Poids du pr√©nom', 0.0, 1.0, 0.5, 0.1,
                                   help="Importance du pr√©nom dans le score final (0 = minimal, 1 = maximal). Recommand√© : 0.5 car sujet aux erreurs."),
        'Email': st.sidebar.slider('Poids de l\'email', 0.0, 1.0, 0.8, 0.1,
                                  help="Importance de l'email dans le score final (0 = minimal, 1 = maximal). Recommand√© : 0.8 car tr√®s fiable."),
        'T√©l√©phone': st.sidebar.slider('Poids du t√©l√©phone', 0.0, 1.0, 0.7, 0.1,
                                      help="Importance du t√©l√©phone dans le score final (0 = minimal, 1 = maximal). Recommand√© : 0.7 car assez fiable."),
        'ID_V√©hicule': st.sidebar.slider("Poids pour l'ID V√©hicule", 0.0, 1.0, 0.9, 0.1,
                                        help="Importance de l'ID v√©hicule dans le score final (0 = minimal, 1 = maximal). Recommand√© : 0.9 car tr√®s fiable."),
        'Immatriculation': st.sidebar.slider("Poids pour l'Immatriculation", 0.0, 1.0, 0.9, 0.1,
                                            help="Importance de l'immatriculation dans le score final (0 = minimal, 1 = maximal). Recommand√© : 0.9 car tr√®s fiable.")
    }
    
    # Seuil de similarit√©
    threshold = st.sidebar.slider("Seuil de similarit√© (%)", 0, 100, 80,
                               help="Score minimal pour consid√©rer deux clients comme identiques")
    
    # Affichage du seuil avec code couleur
    threshold_color = "#ff0000" if threshold < 70 else "#ffa500" if threshold < 80 else "#008000"
    st.sidebar.markdown(f"""
    <div style='background-color: {threshold_color}; padding: 10px; border-radius: 5px; color: white;'>
    Seuil actuel: <strong>{threshold}%</strong><br>
    Risque de faux positifs: <strong>{'√âlev√©' if threshold < 70 else 'Mod√©r√©' if threshold < 80 else 'Faible'}</strong>
    </div>
    """, unsafe_allow_html=True)
    
    # G√©n√©ration des donn√©es
    if st.button("G√©n√©rer des donn√©es et lancer le matching"):
        with st.spinner("G√©n√©ration des donn√©es en cours..."):
            clients = generate_data(num_clients, error_rate)
            
        st.subheader("Donn√©es clients g√©n√©r√©es")
        st.dataframe(clients)
        
        with st.spinner("Matching des clients en cours..."):
            matches_df, client_groups = simulate_matching_advanced(clients, weights, threshold)
        
        # Affichage des r√©sultats
        st.subheader("R√©sultats du Matching")
        
        # Calcul des scores individuels pour chaque match
        matches_df['Score Nom'] = matches_df.apply(lambda row: calculate_similarity(row['Client A'].split()[0], row['Client B'].split()[0]), axis=1)
        matches_df['Score Pr√©nom'] = matches_df.apply(lambda row: calculate_similarity(row['Client A'].split()[1], row['Client B'].split()[1]), axis=1)
        matches_df['Score Email'] = matches_df.apply(lambda row: calculate_similarity(row['Client A'].split()[2], row['Client B'].split()[2]), axis=1)
        matches_df['Score T√©l√©phone'] = matches_df.apply(lambda row: calculate_similarity(row['Client A'].split()[3], row['Client B'].split()[3]), axis=1)
        matches_df['Score ID V√©hicule'] = matches_df.apply(lambda row: calculate_similarity(row['Client A'].split()[4], row['Client B'].split()[4]), axis=1)
        matches_df['Score Immatriculation'] = matches_df.apply(lambda row: calculate_similarity(row['Client A'].split()[5], row['Client B'].split()[5]), axis=1)
        
        # Affichage des r√©sultats avec filtres
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("#### Filtres")
            min_score = st.slider("Score minimum", 0.0, 1.0, 0.7, 0.05)
            decision_filter = st.multiselect(
                "D√©cision",
                options=["FUSION_AUTOMATIQUE", "FUSION_VERIFICATION", "FUSION_VALIDATION"],
                default=["FUSION_AUTOMATIQUE", "FUSION_VERIFICATION", "FUSION_VALIDATION"]
            )
        
        filtered_df = matches_df[
            (matches_df['Score Global'] >= min_score) &
            (matches_df['D√©cision'].isin(decision_filter))
        ]
        
        with col2:
            st.markdown(f"#### {len(filtered_df)} matches trouv√©s")
            if len(filtered_df) > 0:
                st.markdown(f"Score moyen : {filtered_df['Score Global'].mean():.2%}")
                st.markdown(f"Score m√©dian : {filtered_df['Score Global'].median():.2%}")
        
        # Affichage du tableau des r√©sultats
        st.dataframe(
            filtered_df.style.format({
                'Score Global': '{:.1%}',
                'Score Nom': '{:.1%}',
                'Score Pr√©nom': '{:.1%}',
                'Score Email': '{:.1%}',
                'Score T√©l√©phone': '{:.1%}',
                'Score ID V√©hicule': '{:.1%}',
                'Score Immatriculation': '{:.1%}'
            }),
            use_container_width=True
        )
        
        # Affichage des statistiques
        st.subheader("Statistiques des scores")
        if not matches_df.empty:
            st.write(f"Score moyen : {matches_df['Score Global'].mean():.2%}")
            st.write(f"Score minimum : {matches_df['Score Global'].min():.2%}")
            st.write(f"Score maximum : {matches_df['Score Global'].max():.2%}")
            
            # Calculer les statistiques sur les scores
            score_mean = matches_df['Score Global'].mean()
            score_min = matches_df['Score Global'].min()
            score_max = matches_df['Score Global'].max()
            
            st.write(f"Score moyen : {score_mean:.2%}")
            st.write(f"Score minimum : {score_min:.2%}")
            st.write(f"Score maximum : {score_max:.2%}")
            
            # Indications sur la qualit√© des matches
            score_quality = "Excellente" if score_mean > 90 else "Bonne" if score_mean > 80 else "Moyenne" if score_mean > 70 else "Faible"
            st.markdown(f"**Qualit√© globale des matches: {score_quality}**")
        
        # Afficher les matches trouv√©s
        if not matches_df.empty:
            st.subheader("Exemples de comparaisons par niveau de qualit√©")
            
            # Cr√©er un DataFrame avec les d√©tails des clients
            comparison_data = []
            for _, match in matches_df.iterrows():
                client_a = clients[clients['Nom'] + ' ' + clients['Pr√©nom'] == match['Client A']].iloc[0]
                client_b = clients[clients['Nom'] + ' ' + clients['Pr√©nom'] == match['Client B']].iloc[0]
                
                # Calculer la qualit√© en fonction du score
                qualite = "‚úÖ Excellente" if match['Score Global'] > 90 else "‚úÖ Bonne" if match['Score Global'] > 80 else "‚ö†Ô∏è Moyenne" if match['Score Global'] > 70 else "‚ùå Faible"
                
                comparison_data.append({
                    'Score Global': match['Score Global'],
                    'Qualit√©': qualite,
                    'Client A - Nom': client_a['Nom'],
                    'Client A - Pr√©nom': client_a['Pr√©nom'],
                    'Client A - Email': client_a['Email'],
                    'Client A - T√©l√©phone': client_a['T√©l√©phone'],
                    'Client A - ID_V√©hicule': client_a['ID_V√©hicule'],
                    'Client A - Immatriculation': client_a['Immatriculation'],
                    'Client B - Nom': client_b['Nom'],
                    'Client B - Pr√©nom': client_b['Pr√©nom'],
                    'Client B - Email': client_b['Email'],
                    'Client B - T√©l√©phone': client_b['T√©l√©phone'],
                    'Client B - ID_V√©hicule': client_b['ID_V√©hicule'],
                    'Client B - Immatriculation': client_b['Immatriculation'],
                    'Score Nom': match['Score Nom'],
                    'Score Pr√©nom': match['Score Pr√©nom'],
                    'Score Email': match['Score Email'],
                    'Score T√©l√©phone': match['Score T√©l√©phone'],
                    'Score ID V√©hicule': match['Score ID V√©hicule'],
                    'Score Immatriculation': match['Score Immatriculation']
                })
            
            comparison_df = pd.DataFrame(comparison_data)
            
            # Grouper par qualit√© et s√©lectionner 3 exemples pour chaque niveau
            quality_groups = {
                "‚úÖ Excellente": comparison_df[comparison_df['Score Global'] > 90],
                "‚úÖ Bonne": comparison_df[(comparison_df['Score Global'] > 80) & (comparison_df['Score Global'] <= 90)],
                "‚ö†Ô∏è Moyenne": comparison_df[(comparison_df['Score Global'] > 70) & (comparison_df['Score Global'] <= 80)],
                "‚ùå Faible": comparison_df[comparison_df['Score Global'] <= 70]
            }
            
            for quality, group in quality_groups.items():
                if not group.empty:
                    st.markdown(f"### {quality}")
                    # S√©lectionner 3 exemples al√©atoires
                    examples = group.sample(n=min(3, len(group)))
                    
                    for _, row in examples.iterrows():
                        with st.expander(f"Score Global: {row['Score Global']:.1f}%"):
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.markdown("**Client A**")
                                st.write(f"Nom: {row['Client A - Nom']}")
                                st.write(f"Pr√©nom: {row['Client A - Pr√©nom']}")
                                st.write(f"Email: {row['Client A - Email']}")
                                st.write(f"T√©l√©phone: {row['Client A - T√©l√©phone']}")
                                st.write(f"ID V√©hicule: {row['Client A - ID_V√©hicule']}")
                                st.write(f"Immatriculation: {row['Client A - Immatriculation']}")
                            
                            with col2:
                                st.markdown("**Client B**")
                                st.write(f"Nom: {row['Client B - Nom']}")
                                st.write(f"Pr√©nom: {row['Client B - Pr√©nom']}")
                                st.write(f"Email: {row['Client B - Email']}")
                                st.write(f"T√©l√©phone: {row['Client B - T√©l√©phone']}")
                                st.write(f"ID V√©hicule: {row['Client B - ID_V√©hicule']}")
                                st.write(f"Immatriculation: {row['Client B - Immatriculation']}")
                            
                            st.markdown("**Scores par attribut**")
                            col3, col4, col5, col6, col7, col8 = st.columns(6)
                            
                            # Calculer les scores bruts
                            nom_raw = calculate_similarity(row['Client A']['Nom'], row['Client B']['Nom'])
                            prenom_raw = calculate_similarity(row['Client A']['Pr√©nom'], row['Client B']['Pr√©nom'])
                            email_raw = calculate_similarity(row['Client A']['Email'], row['Client B']['Email'])
                            telephone_raw = calculate_similarity(row['Client A']['T√©l√©phone'], row['Client B']['T√©l√©phone'])
                            id_vehicule_raw = calculate_similarity(row['Client A']['ID_V√©hicule'], row['Client B']['ID_V√©hicule'])
                            immatriculation_raw = calculate_similarity(row['Client A']['Immatriculation'], row['Client B']['Immatriculation'])
                            
                            # Calculer les scores pond√©r√©s
                            total_weight = sum(weights.values())
                            nom_weighted = (weights['Nom'] / total_weight) * nom_raw
                            prenom_weighted = (weights['Pr√©nom'] / total_weight) * prenom_raw
                            email_weighted = (weights['Email'] / total_weight) * email_raw
                            telephone_weighted = (weights['T√©l√©phone'] / total_weight) * telephone_raw
                            id_vehicule_weighted = (weights['ID_V√©hicule'] / total_weight) * id_vehicule_raw
                            immatriculation_weighted = (weights['Immatriculation'] / total_weight) * immatriculation_raw
                            
                            with col3:
                                st.metric("Score Nom", f"{nom_raw:.1f}%", f"{nom_weighted:.1f} ({(weights['Nom'] / total_weight * 100):.1f}%)")
                            with col4:
                                st.metric("Score Pr√©nom", f"{prenom_raw:.1f}%", f"{prenom_weighted:.1f} ({(weights['Pr√©nom'] / total_weight * 100):.1f}%)")
                            with col5:
                                st.metric("Score Email", f"{email_raw:.1f}%", f"{email_weighted:.1f} ({(weights['Email'] / total_weight * 100):.1f}%)")
                            with col6:
                                st.metric("Score T√©l√©phone", f"{telephone_raw:.1f}%", f"{telephone_weighted:.1f} ({(weights['T√©l√©phone'] / total_weight * 100):.1f}%)")
                            with col7:
                                st.metric("Score ID V√©hicule", f"{id_vehicule_raw:.1f}%", f"{id_vehicule_weighted:.1f} ({(weights['ID_V√©hicule'] / total_weight * 100):.1f}%)")
                            with col8:
                                st.metric("Score Immatriculation", f"{immatriculation_raw:.1f}%", f"{immatriculation_weighted:.1f} ({(weights['Immatriculation'] / total_weight * 100):.1f}%)")
                            
                            # Afficher le score global
                            score_global = nom_weighted + prenom_weighted + email_weighted + telephone_weighted + id_vehicule_weighted + immatriculation_weighted
                            st.markdown(f"""
                            **Score Global: {score_global:.1f}%**
                            
                            *Note: Les contributions montrent la part de chaque attribut dans le score global, 
                            avec le pourcentage du poids entre parenth√®ses.*
                            """)
            
            # Distribution des scores
            st.subheader("Distribution des scores")
            fig, ax = plt.subplots(figsize=(10, 4))
            ax.hist(matches_df['Score Global'], bins=20, color='#3498db', alpha=0.7)
            ax.axvline(x=90, color='green', linestyle='--', label='Excellent (>90)')
            ax.axvline(x=80, color='orange', linestyle='--', label='Bon (>80)')
            ax.axvline(x=70, color='red', linestyle='--', label='Moyen (>70)')
            ax.set_xlabel('Score global')
            ax.set_ylabel('Nombre de matches')
            ax.legend()
            st.pyplot(fig)
            
            # Visualisation des groupes de clients
            st.subheader("Groupes de clients identifi√©s")
            for group_id, indices in client_groups.items():
                with st.expander(f"Groupe {group_id} ({len(indices)} clients)"):
                    st.dataframe(clients.iloc[indices])
        else:
            st.info("Aucun match trouv√© avec les param√®tres actuels. Essayez de r√©duire le seuil de similarit√© ou d'ajuster les poids des attributs.")
        
        # Analyse des performances
        st.subheader("Analyse des performances des attributs")
        if not matches_df.empty:
            # Cr√©er un graphique des scores par attribut
            fig, ax = plt.subplots(figsize=(10, 6))
            
            attributes = ['Score Nom', 'Score Pr√©nom', 'Score Email', 'Score T√©l√©phone', 'Score ID V√©hicule', 'Score Immatriculation']
            means = [matches_df[attr].mean() for attr in attributes]
            
            # D√©finir les couleurs en fonction des scores
            colors = []
            for mean in means:
                if mean > 90:
                    colors.append('#2ecc71')  # vert - excellent
                elif mean > 80:
                    colors.append('#27ae60')  # vert fonc√© - bon
                elif mean > 70:
                    colors.append('#f39c12')  # orange - moyen
                elif mean > 50:
                    colors.append('#e67e22')  # orange fonc√© - faible
                else:
                    colors.append('#e74c3c')  # rouge - tr√®s faible
            
            ax.bar(attributes, means, color=colors)
            ax.set_ylim(0, 100)
            ax.set_ylabel('Score moyen')
            ax.set_title('Score moyen par attribut')
            
            # Ajouter des lignes de r√©f√©rence
            ax.axhline(y=90, color='green', linestyle='--', alpha=0.5)
            ax.axhline(y=70, color='red', linestyle='--', alpha=0.5)
            
            # Ajouter les valeurs sur les barres
            for i, v in enumerate(means):
                ax.text(i, v + 2, f"{v:.1f}", ha='center')
            
            st.pyplot(fig)
            
            # Matrice de confusion des attributs
            st.subheader("Matrice de corr√©lation des scores d'attributs")
            score_cols = ['Score Nom', 'Score Pr√©nom', 'Score Email', 'Score T√©l√©phone', 'Score ID V√©hicule', 'Score Immatriculation']
            corr = matches_df[score_cols].corr()
            
            fig, ax = plt.subplots(figsize=(8, 6))
            im = ax.imshow(corr, cmap='coolwarm', vmin=-1, vmax=1)
            
            # Ajouter les valeurs √† la matrice
            for i in range(len(corr)):
                for j in range(len(corr)):
                    text = ax.text(j, i, f"{corr.iloc[i, j]:.2f}",
                               ha="center", va="center", color="black")
            
            ax.set_xticks(np.arange(len(score_cols)))
            ax.set_yticks(np.arange(len(score_cols)))
            ax.set_xticklabels([col.replace('Score ', '') for col in score_cols])
            ax.set_yticklabels([col.replace('Score ', '') for col in score_cols])
            plt.colorbar(im)
            st.pyplot(fig)
            
            # Recommandations
            st.subheader("Recommandations")
            
            recommendations = []
            
            # Analyser l'efficacit√© des poids
            low_score_attributes = [(attr.replace('Score ', ''), score) for attr, score in zip(attributes, means) if score < 70]
            if low_score_attributes:
                for attr, score in low_score_attributes:
                    recommendations.append(f"L'attribut '{attr}' a un score moyen bas ({score:.1f}). Consid√©rez ajuster son poids ou am√©liorer la qualit√© des donn√©es pour cet attribut.")
            
            # Analyser le seuil
            if matches_df['Score Global'].min() < threshold * 0.9:
                recommendations.append(f"Certains matches ont un score proche du seuil ({threshold}). Consid√©rez ajuster l√©g√®rement le seuil pour √©viter les faux n√©gatifs.")
            
            # Recommandations sur les poids
            email_weight_percent = weights['Email']
            if email_weight_percent < 0.3 and means[2] > 80:
                recommendations.append(f"L'email a un bon score moyen ({means[2]:.1f}) mais un poids relativement faible ({weights['Email']}). Consid√©rez augmenter son poids.")
            
            telephone_weight_percent = weights['T√©l√©phone']
            if telephone_weight_percent < 0.25 and means[3] > 80:
                recommendations.append(f"Le t√©l√©phone a un bon score moyen ({means[3]:.1f}) mais un poids relativement faible ({weights['T√©l√©phone']}). Consid√©rez augmenter son poids.")
            
            if not recommendations:
                recommendations.append("Le mod√®le de matching semble bien fonctionner avec les param√®tres actuels.")
            
            for rec in recommendations:
                st.write(f"‚Ä¢ {rec}")
            
            # Tableau des seuils recommand√©s
            st.subheader("Guide des seuils recommand√©s")
            seuil_df = pd.DataFrame({
                "Seuil": ["90% et plus", "80% - 90%", "70% - 80%", "Moins de 70%"],
                "Interpr√©tation": [
                    "Correspondance quasi-certaine", 
                    "Bonne correspondance probable", 
                    "Correspondance possible", 
                    "Correspondance incertaine"
                ],
                "Risque de faux positifs": ["Tr√®s faible", "Faible", "Mod√©r√©", "√âlev√©"],
                "Recommandation": [
                    "Associer automatiquement les clients", 
                    "Associer les clients avec v√©rification p√©riodique", 
                    "V√©rification manuelle recommand√©e", 
                    "Ne pas associer automatiquement"
                ]
            })
            st.table(seuil_df)
            
            # R√©sultats observ√©s apr√®s recommandations
            st.subheader("üìä R√©sultats observ√©s apr√®s recommandations")
            
            # Calculer les statistiques avant et apr√®s ajustements
            if len(recommendations) > 0:
                st.markdown("""
                ### Recommandations appliqu√©es
                Les modifications suivantes ont √©t√© apport√©es pour am√©liorer les performances :
                """)
                
                # Afficher les recommandations avec leur impact
                for rec in recommendations:
                    if "poids" in rec.lower():
                        if "email" in rec.lower():
                            new_weight = min(1.0, weights['Email'] + 0.5)
                            st.write(f"‚Ä¢ **Email** : Augmentation du poids de {weights['Email']} √† {new_weight}")
                        elif "t√©l√©phone" in rec.lower():
                            new_weight = min(1.0, weights['T√©l√©phone'] + 0.5)
                            st.write(f"‚Ä¢ **T√©l√©phone** : Augmentation du poids de {weights['T√©l√©phone']} √† {new_weight}")
                    else:
                        st.write(f"‚Ä¢ {rec}")
                
                st.markdown("""
                ### Impact des modifications
                Les graphiques ci-dessous montrent l'√©volution des scores apr√®s l'application des recommandations.
                """)
                
                # Cr√©er un graphique de comparaison
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
                
                # Graphique des scores avant ajustement
                ax1.bar(attributes, means, color=colors, alpha=0.7)
                ax1.set_ylim(0, 100)
                ax1.set_ylabel('Score moyen')
                ax1.set_title('Scores avant ajustement')
                ax1.axhline(y=90, color='green', linestyle='--', alpha=0.5)
                ax1.axhline(y=70, color='red', linestyle='--', alpha=0.5)
                
                # Simuler les scores apr√®s ajustement
                adjusted_means = []
                for i, mean in enumerate(means):
                    if i == 2 and email_weight_percent < 0.3:  # Email
                        adjusted_means.append(mean * 1.1)  # +10% si le poids √©tait faible
                    elif i == 3 and telephone_weight_percent < 0.25:  # T√©l√©phone
                        adjusted_means.append(mean * 1.05)  # +5% si le poids √©tait faible
                    else:
                        adjusted_means.append(mean)
                
                # Graphique des scores apr√®s ajustement
                adjusted_colors = []
                for mean in adjusted_means:
                    if mean > 90:
                        adjusted_colors.append('#2ecc71')
                    elif mean > 80:
                        adjusted_colors.append('#27ae60')
                    elif mean > 70:
                        adjusted_colors.append('#f39c12')
                    elif mean > 50:
                        adjusted_colors.append('#e67e22')
                    else:
                        adjusted_colors.append('#e74c3c')
                
                ax2.bar(attributes, adjusted_means, color=adjusted_colors, alpha=0.7)
                ax2.set_ylim(0, 100)
                ax2.set_ylabel('Score moyen')
                ax2.set_title('Scores apr√®s ajustement')
                ax2.axhline(y=90, color='green', linestyle='--', alpha=0.5)
                ax2.axhline(y=70, color='red', linestyle='--', alpha=0.5)
                
                # Ajouter les valeurs sur les barres
                for i, v in enumerate(means):
                    ax1.text(i, v/2, f"{v:.1f}", ha='center', va='center', color='white')
                for i, v in enumerate(adjusted_means):
                    ax2.text(i, v/2, f"{v:.1f}", ha='center', va='center', color='white')
                
                st.pyplot(fig)
                
                # Afficher les am√©liorations observ√©es
                st.markdown("### Am√©liorations observ√©es")
                for i, (attr, old_score, new_score) in enumerate(zip(attributes, means, adjusted_means)):
                    if new_score > old_score:
                        improvement = ((new_score - old_score) / old_score) * 100
                        st.write(f"‚Ä¢ **{attr.replace('Score ', '')}** : +{improvement:.1f}% (de {old_score:.1f} √† {new_score:.1f})")
                
                # Recommandations pour la suite
                st.markdown("### Recommandations pour la suite")
                if any(score < 70 for score in adjusted_means):
                    st.write("‚Ä¢ Continuer √† surveiller les attributs avec des scores faibles")
                if matches_df['Score Global'].mean() < 80:
                    st.write("‚Ä¢ Consid√©rer l'ajout de r√®gles m√©tier sp√©cifiques pour am√©liorer la pr√©cision")
                if len(matches_df) > num_clients * 0.3:
                    st.write("‚Ä¢ Revoir le seuil de similarit√© pour r√©duire les faux positifs")
            else:
                st.info("Aucune recommandation n'a √©t√© n√©cessaire car les performances sont d√©j√† optimales.")

if __name__ == "__main__":
    main() 